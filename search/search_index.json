{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83c\udfd7\ufe0f\ud83c\udfd7\ufe0f RHEL Image Mode Demo use cases \ud83c\udfd7\ufe0f\ud83c\udfd7\ufe0f","text":"<p>Welcome to this demo content for Red Hat Enterprise Linux Image mode! This content provides a quick way to know more and try out the Image Mode for RHEL, with many use cases that can be easily reproduced in your environment.</p> <p>Below you can find some external resources from Red Hat websites and upstream projects on the topic.</p> <p> Get Started!</p>"},{"location":"#rhel-image-mode","title":"RHEL Image mode","text":"<ul> <li>RHEL Image Mode landing page on Red Hat Website</li> <li>RHEL Image Mode quickstart on Red Hat Blog</li> <li>RHEL Image Mode documentation on Red Hat Website</li> <li>Red Hat Developers - Getting Started with RHEL Image Mode</li> <li>A new state of mind with image mode for RHEL on Red Hat Blog</li> </ul>"},{"location":"#bootc-upstream-projects","title":"bootc Upstream projects","text":"<ul> <li>bootc project on GitHub</li> <li>bootc-image-builder project on GitHub</li> </ul>"},{"location":"getting-started/contributing/","title":"How to contribute to the project","text":"<p>Contributions are more than welcome, as it's the only way to ensure quality and keep projects alive, and to keep consistency it's great to have some guidance when starting to submit and be part of the changes.</p> <p>Here are a few guidelines that can be useful when contributing.</p>"},{"location":"getting-started/contributing/#project-structure","title":"Project structure","text":"<p>The project is structured to host:</p> <ul> <li>the operative files (Containerfiles, additional configurations) in the use cases folder</li> <li>the documentation for the doc website https://redhat-cop.github.io/redhat-image-mode-demo/ in the docs folder</li> </ul> <p>The documentation uses mkdocs with the mkdocs Material theme to render the markdown pages into the site.</p>"},{"location":"getting-started/contributing/#working-on-existing-use-cases","title":"Working on existing use cases","text":"<p>If you want to contribute with fixes or enhancement for already existing use cases, you can go straight to the content in the docs/use-cases/ folder of the corresponding use case and start working on it. If changes are needed on the core part, you can work in the corresponding dedicated folder under use-cases/.</p>"},{"location":"getting-started/contributing/#working-on-new-use-cases","title":"Working on new use cases","text":""},{"location":"getting-started/contributing/#operating-on-the-use-case-folders","title":"Operating on the use case folders","text":"<p>To contribute with new use cases, you can create a new folder in the docs/use-cases/ and use-cases/ folders with a meaningful name. </p> <p>The README.md of each single use case should contain minimal information about the use case and a link to the Document Site section corresponding to it.</p> <p>To include snippets within the repo you can follow the Pymdownx-snippets plugin documentation. </p> <p>Paths are relative to the root of the repository, below an example to include a snippet coming from use-cases/bootc-container-anaconda-ks folder into the doc file in *docs/use-cases/bootc-container-anaconda-ks\":</p> Including a snippet in a page<pre><code>```\n--8&lt;-- \"use-cases/bootc-container-anaconda-ks/ks.cfg\"\n```\n</code></pre> <p>When directly linking files within the repo, use direct linking to the GitHub repo, accessible using the variables {{ config.repo_url }}{{ config.edit_uri }} that points to the root (/blob/main/) folder of the repository, to avoid direct download within the browser.</p>"},{"location":"getting-started/contributing/#adapting-the-mkdocs-configuration","title":"Adapting the mkdocs configuration","text":"<p>After adding a new use case it is enough to add the new use case to the nav section of the mkdocs.yml configuration file under the \"Use Cases\" section with a title and the link:</p> Example use-case line in mkdocs.yml<pre><code>    - Generate a RHEL AMI image for an AWS instance using bootc-image-builder: use-cases/bootc-image-builder-ami/README.md\n</code></pre>"},{"location":"getting-started/introduction/","title":"Introducing RHEL Image mode","text":""},{"location":"getting-started/introduction/#what-is-rhel-image-mode","title":"What is RHEL Image Mode?","text":"<p>RHEL Image mode is a new approach for operating system deployment that enables users to create, deploy and manage Red Hat Enterprise Linux as a bootc container image.</p> <p>This approach simplifies operations across the enterprise, allowing developers, operations teams and solution providers to use the same container-native tools and techniques to manage everything from applications to the underlying OS.</p>"},{"location":"getting-started/introduction/#how-is-rhel-image-mode-different","title":"How is RHEL Image Mode different?","text":"<p>Due to the container-oriented nature, RHEL Image mode opens up to a unification and standardization of OS management and deployment, allowing the integration with existing CI/CD workflows and/or GitOps, reducing complexity.</p> <p>RHEL Image mode also helps increasing security as the content, updates and patches are predictable and atomic, preventing manual modification of core services, packages and applications for a guaranteed consistency at scale.</p>"},{"location":"getting-started/quickstart/","title":"\ud83c\udfaf\ud83c\udfaf Let's get started \ud83c\udfaf\ud83c\udfaf","text":"<p>First of all, clone the repo:</p> <pre><code>git clone https://github.com/redhat-cop/redhat-image-mode-demo\n</code></pre> <p>Creating a container for RHEL Image Mode is as easy as writing and running a Containerfile like this:</p> <p>Warning</p> <p>To build images using RHEL bootc image you need a RHEL System with a valid subscription attached to it. For non-production workloads, you can register for a free Red Hat developer subscription.</p> <pre><code>FROM registry.redhat.io/rhel10/rhel-bootc:10.1\n</code></pre> <p>You can proceed customizing the image, adding users, packages, configurations, etc following the Dockerfile Reference as well as providing informative/documentation layers (MAINTAINER, LABEL, etc) following the best-practices of Containerfile creation.</p> <p>Tip</p> <p>Some Dockerfile Directives (EXPOSE, ENTRYPOINT, ENV, among them) are ignored during RHEL Image deployment on a system, see the documentation for more details.</p>"},{"location":"getting-started/review-and-test-changes/","title":"Reviewing and testing the changes","text":"<p>Since documentation can contain snippets and markdown from Material for MkDocs and pymdown-extensions projects, to properly test changes, whether while writing content or reviewing a Pull Request, a Containerfile is provided with the minimum packages to run the serving command for MkDocs.</p> Review Containerfile <pre><code>  FROM registry.access.redhat.com/ubi9/python-312\n  RUN pip3 install mkdocs mkdocs-material mkdocs-macros-plugin mkdocs mkdocs-mermaid2-plugin\n  ENTRYPOINT mkdocs serve -a 0.0.0.0:8000\n</code></pre>"},{"location":"getting-started/review-and-test-changes/#instructions-to-test-changes","title":"Instructions to test changes","text":""},{"location":"getting-started/review-and-test-changes/#building-the-container-image","title":"Building the container image","text":"<p>While writing content, from the root folder of the repository, simply build the image:</p> <pre><code>podman build -t mkdocs-testing .\n</code></pre>"},{"location":"getting-started/review-and-test-changes/#running-the-container","title":"Running the container","text":"Read here if you are reviewing a Pull Request <p>When reviewing a pull request, you need to create a temporary branch and fetch the content into it. Assuming user kubealex proposed a Pull Request involving the testing branch: <pre><code>git checkout -b kubealex-testing\ngit pull https://github.com/kubealex/redhat-image-mode-demo.git testing\n</code></pre></p> <p>After the image is built, simply run the container mounting the current folder:</p> <pre><code>export HOST_PORT=8000\npodman run -it --user $(id -u) --network podman -p $HOST_PORT:8000 -v ./:/opt/app-root/src:rw,Z mkdocs-testing\n</code></pre> <p>Replace the HOST_PORT variable with a free port on the host you are running the container.</p> <p>If everything is working fine, the webserver will be listening on the desired port and reachable at the address http://localhost:8000</p> <p></p>"},{"location":"use-cases/bootc-container-anaconda-ks/","title":"Use Case - RHEL Bootc container as a setup source for Kickstart/Anaconda","text":"<p>In this example, we will expand the image we built in the Apache bootc use case that you can use as a reference for details. This way, we will be able to streamline the creation of VMs based on a frozen, immutable configuration that will take few seconds to be deployed.</p> Tip <p>\"We will stay on RHEL9 to further show how to perform major upgrades in a following example.\"</p> <p>The Containerfile.anaconda in the example:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs Apache Server</li> <li>Enables the systemd unit for httpd</li> <li>Adds a custom index.html</li> <li>Customizes the Message of the day</li> </ul> Review Containerfile.anaconda <pre><code>LABEL org.opencontainers.image.authors=\"alerossi@redhat.com\"\nFROM registry.redhat.io/rhel9/rhel-bootc:9.7\nRUN dnf -y install tmux mkpasswd\nRUN pass=$(mkpasswd --method=SHA-512 --rounds=4096 redhat) &amp;&amp; useradd -m -G wheel bootc-user -p $pass\nRUN echo \"%wheel        ALL=(ALL)       NOPASSWD: ALL\" &gt; /etc/sudoers.d/wheel-sudo\nRUN dnf -y install httpd &amp;&amp; \\\n    systemctl enable httpd &amp;&amp; \\\n    mv /var/www /usr/share/www &amp;&amp; \\\n    sed -ie 's,/var/www,/usr/share/www,' /etc/httpd/conf/httpd.conf\nRUN echo \"Welcome to the bootc-http instance!\" &gt; /usr/share/www/html/index.html\nRUN echo \"This is a RHEL 9.7 VM installed using a bootable container as source!\" &gt; /etc/motd.d/10-first-setup.motd\nEXPOSE 80\nCMD [ \"/sbin/init\" ]\n</code></pre>"},{"location":"use-cases/bootc-container-anaconda-ks/#pre-requisites","title":"Pre-requisites","text":"<p>You need a Container registry to push the image and make it available. I suggest creating an account on Quay.io. During the configuration I will be using my username, kubealex, for the demo.</p>"},{"location":"use-cases/bootc-container-anaconda-ks/#building-the-image","title":"Building the image","text":"<p>From the root folder of the repository, switch to the use case directory:</p> <pre><code>cd use-cases/bootc-container-anaconda\n</code></pre> <p>You can build the image right from the Containerfile using Podman:</p> <pre><code>podman build -f Containerfile.anaconda -t rhel-bootc-vm:httpd .\n</code></pre>"},{"location":"use-cases/bootc-container-anaconda-ks/#tagging-and-pushing-the-image","title":"Tagging and pushing the image","text":"<p>To tag and push the image you can simply run (replace YOURQUAYUSERNAME with the account name):</p> <pre><code>export QUAY_USER=YOURQUAYUSERNAME\n</code></pre> <pre><code>podman tag rhel-bootc-vm:httpd quay.io/$QUAY_USER/rhel-bootc-vm:httpd\n</code></pre> <p>Log-in to Quay.io:</p> <pre><code>podman login -u $QUAY_USER quay.io\n</code></pre> <p>And push the image:</p> <pre><code>podman push quay.io/$QUAY_USER/rhel-bootc-vm:httpd\n</code></pre> <p>You can now browse to https://quay.io/repository/YOURQUAYUSERNAME/rhel-bootc-httpd?tab=settings and ensure that the repository is set to \"Public\".</p> <p></p>"},{"location":"use-cases/bootc-container-anaconda-ks/#install-rhel-97-using-the-resulting-image","title":"Install RHEL 9.7 using the resulting image","text":""},{"location":"use-cases/bootc-container-anaconda-ks/#prepare-install-media-and-review-the-kickstart-file","title":"Prepare install media and review the kickstart file","text":"<p>RHEL 9.7 ISO images are available on the Red Hat Developer portal and for this use case we will only need the boot image.</p> <p>Save the image and place it in the use case folder with the name rhel9.iso</p> <p>The kickstart file is a very simple one:</p> <ul> <li>Configures text install</li> <li>Creates a root user with password redhat</li> <li>Sets up basic partitioning</li> </ul> <p>What is relevant is the ostreecontainer directive, that references the container image we just built as a source for the installation!</p> Review ks.cfg <pre><code>text\nreboot\nnetwork --bootproto=dhcp\n\nzerombr\nclearpart --all --initlabel --disklabel=gpt\npart biosboot  --size=1    --fstype=biosboot\npart /boot --size=1024 --fstype=ext4 --label=boot\npart /boot/efi --size=100  --fstype=efi\npart / --size=1000 --fstype=xfs --grow\n\nkeyboard us\nlang en_US\ntimezone Europe/Rome\n\nrootpw redhat\n\nostreecontainer --no-signature-verification  --url=quay.io/YOURQUAYUSERNAME/rhel-bootc-vm:httpd\n#  ostreecontainer --no-signature-verification  --url=quay.io/kubealex/rhel-bootc-vm:httpd\n</code></pre>"},{"location":"use-cases/bootc-container-anaconda-ks/#creating-the-virtual-machine-in-kvm","title":"Creating the Virtual Machine in KVM","text":"<p>You are now ready to spin-up a Virtual Machine using the downloaded boot image for RHEL 9.7, injecting and using the kickstart to perform an unattended installation.</p> <pre><code>virt-install --name rhel9-server \\\n--memory 4096 \\\n--vcpus 2 \\\n--disk size=20 \\\n--network network=default \\\n--location ./rhel9.iso \\\n--os-variant rhel9.7 \\\n--initrd-inject ks.cfg \\\n--extra-args \"inst.ks=file:/ks.cfg\"\n</code></pre> <p>In a few seconds, the VM will boot and start the installation, grabbing the container image as a source to perform the configuration:</p> <p></p> <p>Based on the connection, it can take a while to fetch the container image and complete the setup. Once it is completed, you can log-in with the bootc-user/redhat credentials, and you will see the custom Message Of The Day (MOTD) we added in our Containerfile!</p> <pre><code>This is a RHEL 9.7 VM installed using a bootable container as a source!\n</code></pre>"},{"location":"use-cases/bootc-container-httpd/","title":"Use Case - Running a bootc container providing Apache HTTP server","text":"<p>In this example, we will build a container image from a Containerfile and we will then use it as a source for a VM.</p> <p>The Containerfile in the example:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs Apache Server</li> <li>Enables the systemd unit for httpd</li> <li>Adds a custom index.html</li> </ul> Review Containerfile.httpd <pre><code>LABEL org.opencontainers.image.authors=\"alerossi@redhat.com\"\nFROM registry.redhat.io/rhel10/rhel-bootc:10.1\nRUN dnf -y install tmux mkpasswd\nRUN pass=$(mkpasswd --method=SHA-512 --rounds=4096 redhat) &amp;&amp; useradd -m -G wheel bootc-user -p $pass\nRUN echo \"%wheel        ALL=(ALL)       NOPASSWD: ALL\" &gt; /etc/sudoers.d/wheel-sudo\nRUN dnf -y install httpd &amp;&amp; \\\n    systemctl enable httpd &amp;&amp; \\\n    mv /var/www /usr/share/www &amp;&amp; \\\n    sed -ie 's,/var/www,/usr/share/www,' /etc/httpd/conf/httpd.conf\nCOPY files/index.html /usr/share/www/html/index.html\nEXPOSE 80\n</code></pre>"},{"location":"use-cases/bootc-container-httpd/#building-the-image","title":"Building the image","text":"<p>From the root folder of the repository, switch to the use case directory:</p> <pre><code>cd use-cases/bootc-container-httpd\n</code></pre> <p>To build the image:</p> <pre><code>podman build -f Containerfile.httpd -t rhel-bootc-httpd .\n</code></pre>"},{"location":"use-cases/bootc-container-httpd/#testing-the-image","title":"Testing the image","text":"<p>You can now test it using:</p> <pre><code>podman run -it --name rhel-bootc-httpd --hostname rhel-bootc-httpd -p 8080:80 rhel-bootc-httpd\n</code></pre> <p>Note: The \"-p 8080:80\" part forwards the container's http port to the port 8080 on the host to test that it is working.</p> <p>The container will now start and a login prompt will appear.</p> <p>On another terminal tab or in your browser, you can verify that the httpd server is working and serving traffic.</p> <p>Terminal</p> <pre><code> ~ \u2593\u2592\u2591 curl localhost:8080\n</code></pre> <p>Browser</p> <p></p>"},{"location":"use-cases/bootc-container-httpd/#exploring-the-container","title":"Exploring the container","text":"<p>If you are curious, you can easily log-in to the container using the prompt coming from the execution and the bootc-user/redhat user and password.</p> <p>From here, you can verify that:</p> <ul> <li>The user has sudo privileges</li> </ul> <pre><code>[bootc-user@rhel-bootc-bootc ~]$ sudo su\nbash-5.1# whoami\nroot\n</code></pre> <ul> <li>There's systemd running</li> </ul> <pre><code>bash-5.1# systemctl status | more\n\u25cf rhel-bootc-httpd\n    State: running\n    Units: 234 loaded (incl. loaded aliases)\n     Jobs: 0 queued\n   Failed: 0 units\n    Since: Fri 2024-07-19 08:19:28 UTC; 1min 57s ago\n</code></pre> <ul> <li>Apache is loaded as a systemd unit</li> </ul> <pre><code>bash-5.1# systemctl status httpd\n\u25cf httpd.service - The Apache HTTP Server\n     Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; preset: disabled)\n     Active: active (running) since Fri 2024-07-19 08:19:29 UTC; 2min 28s ago\n       Docs: man:httpd.service(8)\n   Main PID: 90 (httpd)\n     Status: \"Total requests: 1; Idle/Busy workers 100/0;Requests/sec: 0.00719; Bytes served/sec:   2 B/sec\"\n      Tasks: 177 (limit: 1638)\n     Memory: 22.0M\n        CPU: 159ms\n     CGroup: /system.slice/httpd.service\n             \u251c\u2500 90 /usr/sbin/httpd -DFOREGROUND\n             \u251c\u2500115 /usr/sbin/httpd -DFOREGROUND\n             \u251c\u2500117 /usr/sbin/httpd -DFOREGROUND\n             \u251c\u2500118 /usr/sbin/httpd -DFOREGROUND\n             \u2514\u2500119 /usr/sbin/httpd -DFOREGROUND\n</code></pre>"},{"location":"use-cases/bootc-container-replace/","title":"Use Case - Applying a different RHEL container image to an existing VM","text":"<p>Our team is looking to improve performances and test different configurations. We created our new and shiny image with Apache HTTPD and MariaDB, but you are exploring alternatives and want to use Nginx and PostgreSQL as some of your team members are more familiar with that stack.</p> <p>We will then create an alternative image, with a dedicated tag, that will help our fellow colleagues in their efforts. Instead of redeploying the VM from scratch, we are going to use bootc to change the reference of the image in our existing VM to use it for configuring the system!</p> <p>The Containerfile.replace is similar to the one in the Image Upgrade use case:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs nginx server</li> <li>Enables the systemd unit for nginx</li> <li>Adds a custom index.html</li> <li>Customizes the Message of the day</li> <li>Add an additional message of the day with the new release notes</li> <li>Add postgresql-server package and vim</li> <li>Enable the postgresql-server systemd unit</li> </ul> <p>Since the bootc switch command will preserve the /var and /etc content, we will use a workaround to create the needed dirs for Nginx and Postgresql leveraging systemd-tmpfiles and systemd-sysusers to ensure users are in place.</p> Review Containerfile.replace <pre><code>LABEL org.opencontainers.image.authors=\"alerossi@redhat.com\"\nFROM registry.redhat.io/rhel10/rhel-bootc:10.1\nRUN dnf -y install tmux mkpasswd\nRUN pass=$(mkpasswd --method=SHA-512 --rounds=4096 redhat) &amp;&amp; useradd -m -G wheel bootc-user -p $pass\nRUN echo \"%wheel        ALL=(ALL)       NOPASSWD: ALL\" &gt; /etc/sudoers.d/wheel-sudo\nRUN dnf -y install nginx &amp;&amp; \\\n    systemctl enable nginx\nRUN echo \"Welcome to the bootc-nginx instance!\" &gt; /usr/share/nginx/html/index.html\nRUN echo \"This is a RHEL 10 VM installed using a bootable container as an rpm-ostree source!\" &gt; /etc/motd.d/10-first-setup.motd\nRUN echo \"This server is equipped with Nginx and PostgreSQL\" &gt; /etc/motd.d/20-replace.motd\nRUN dnf -y install postgresql postgresql-server vim &amp;&amp; \\\n    dnf clean all &amp;&amp; \\\n    rm -rf /var/cache /var/log/dnf &amp;&amp; \\\n    systemctl enable postgresql\nCOPY ./files/sysusers.d/ /usr/lib/sysusers.d/\nCOPY ./files/tmpfiles.d/ /usr/lib/tmpfiles.d/\nEXPOSE 80 5432\n</code></pre>"},{"location":"use-cases/bootc-container-replace/#building-the-image","title":"Building the image","text":"<p>From the root folder of the repository, switch to the use case directory:</p> <pre><code>cd use-cases/bootc-container-replace\n</code></pre> <p>You can build the image right from the Containerfile using Podman:</p> <pre><code>podman build -f Containerfile.replace -t rhel-bootc-vm:nginx .\n</code></pre>"},{"location":"use-cases/bootc-container-replace/#testing-the-image","title":"Testing the image","text":"<p>You can now test it using:</p> <pre><code>podman run -it --name rhel-bootc-vm-nginx --hostname rhel-bootc-vm-nginx -p 8080:80 -p 5432:5432 rhel-bootc-vm:nginx\n</code></pre> <p>Note: The \"-p 8080:80\" -p 5432:5432 part forwards the container's http and postgresql port to the port 8080 and 3306 on the host to test that nginx and postgresql are working.</p> <p>The container will now start and a login prompt will appear.</p>"},{"location":"use-cases/bootc-container-replace/#testing-nginx","title":"Testing Nginx","text":"<p>On another terminal tab or in your browser, you can verify that the httpd server is working and serving traffic.</p> <p>Terminal</p> <pre><code> ~ \u2593\u2592\u2591 curl localhost:8080                                                                                                           \u2591\u2592\u2593 \u2714  11:59:44\nWelcome to the bootc-nginx instance!\n</code></pre> <p>Browser</p> <p></p>"},{"location":"use-cases/bootc-container-replace/#testing-postgresql","title":"Testing Postgresql","text":"<p>From the login prompt, login as bootc-user/redhat and impersonate the root user:</p> <pre><code>[bootc-user@rhel-bootc-vm-nginx ~]$ sudo -i\n[root@rhel-bootc-vm-nginx ~]#\n</code></pre> <p>Initialize PostgreSQL db and config:</p> <pre><code>[root@rhel-bootc-vm-nginx ~]# postgresql-setup --initdb\n * Initializing database in '/var/lib/pgsql/data'\n * Initialized, logs are in /var/lib/pgsql/initdb_postgresql.log\n</code></pre> <p>You will now be able to restart the postgresql systemd unit and test the connection:</p> <pre><code>[root@rhel-bootc-vm-nginx ~]# systemctl restart postgresql\n[root@rhel-bootc-vm-nginx ~]# su - postgres\n[postgres@rhel-bootc-vm-nginx ~]$ psql\npsql (13.14)\nType \"help\" for help.\n\npostgres=#\n</code></pre>"},{"location":"use-cases/bootc-container-replace/#tagging-and-pushing-the-image","title":"Tagging and pushing the image","text":"<p>To tag and push the image you can simply run (replace YOURQUAYUSERNAME with the account name):</p> <pre><code>export QUAY_USER=YOURQUAYUSERNAME\n</code></pre> <pre><code>podman tag rhel-bootc-vm:nginx quay.io/$QUAY_USER/rhel-bootc-vm:nginx\n</code></pre> <p>Log-in to Quay.io:</p> <pre><code>podman login -u $QUAY_USER quay.io\n</code></pre> <p>And push the image:</p> <pre><code>podman push quay.io/$QUAY_USER/rhel-bootc-vm:nginx\n</code></pre> <p>You can now browse to https://quay.io/repository/YOURQUAYUSERNAME/rhel-bootc-httpd?tab=settings and ensure that the repository is set to \"Public\".</p> <p></p>"},{"location":"use-cases/bootc-container-replace/#updating-the-vm-with-the-newly-created-image","title":"Updating the VM with the newly created image","text":"<p>The first thing to do is logging in the VM updated in the previous use case:</p> <pre><code> ~ \u2593\u2592\u2591 ssh bootc-user@192.168.124.16\nbootc-user@192.168.124.16's password:\nThis is a RHEL VM installed using a bootable container as source!\nThis server now supports MariaDB as a database, after last update\nLast login: Mon Jul 29 12:12:51 2024 from 192.168.124.1\n[bootc-user@localhost ~]$\n</code></pre> <p>Verify that bootc is installed:</p> <pre><code>[bootc-user@localhost ~]$ bootc --help\nDeploy and transactionally in-place with bootable container images.\n\nThe `bootc` project currently uses ostree-containers as a backend to support a model of bootable container images.  Once installed, whether directly via `bootc install` (executed as part of a container) or via another mechanism such as an OS installer tool, further updates can be pulled via e.g. `bootc upgrade`.\n\nChanges in `/etc` and `/var` persist.\n\nUsage: bootc &lt;COMMAND&gt;\n\nCommands:\n  upgrade      Download and queue an updated container image to apply\n  switch       Target a new container image reference to boot\n  edit         Apply full changes to the host specification\n  status       Display status\n  usr-overlay  Add a transient writable overlayfs on `/usr` that will be discarded on reboot\n  install      Install the running container to a target\n  help         Print this message or the help of the given subcommand(s)\n\nOptions:\n  -h, --help   Print help (see a summary with '-h')\n</code></pre> <p>Note that among the options we have the switch option that we will be using in this use case. The switch option allows checking, fetching and using a different container image to replace the current configuration and spin up a new rpm-ostree image for the system.</p> <p>In our case we will switch from rhel-bootc-vm:httpd to rhel-bootc-vm:nginx image.</p> <p>The switch command requires higher privileges to run, let's perform the change!</p> <pre><code>[bootc-user@localhost ~]$ sudo bootc switch quay.io/kubealex/rhel-bootc-vm:nginx\nlayers already present: 69; layers needed: 7 (182.7 MB)\n 426 B [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588] (0s) Fetched layer sha256:8a192c7a518d                                                                                                                                                                                                                                                                                                                                            Queued for next boot: quay.io/kubealex/rhel-bootc-vm:nginx\n  Version: 9.20240714.0\n  Digest: sha256:e9dc2975eea3510044934fde745c296b734e8ca6f76add0e92c350e73db54620\n</code></pre> <p>In this case, unlike last time, the layers to retrieve were many more, as we changed big parts of the previous image. At the end of the process, it queued the actual switch after reboot. Let's verify that postgres and nginx are still not present at this time, and proceed with a reboot:</p> <pre><code>[bootc-user@localhost ~]$ systemctl status nginx postgresql\nUnit nginx.service could not be found.\nUnit postgresql.service could not be found.\n[bootc-user@localhost ~]$ sudo reboot\n</code></pre> <p>Let's log back in!</p> <pre><code> ~/\u2593\u2592\u2591 ssh bootc-user@192.168.124.16\nbootc-user@192.168.124.16's password:\nThis is a RHEL 10 VM installed using a bootable container as an rpm-ostree source!\nThis server is equipped with Nginx and PostgreSQL\nLast login: Mon Jul 29 12:26:13 2024 from 192.168.124.1\n</code></pre> <p>You can already see that something changed, we have a different line in our message of the day, let's test if nginx and Postgresql are running and working!</p> <p>Initialize the DB:</p> <pre><code>[root@rhel-bootc-vm-nginx ~]# postgresql-setup --initdb\n * Initializing database in '/var/lib/pgsql/data'\n * Initialized, logs are in /var/lib/pgsql/initdb_postgresql.log\n</code></pre> <p>Restart the PGSQL service:</p> <pre><code>[root@rhel-bootc-vm-nginx ~]# systemctl restart postgresql\n</code></pre> <p>And verify everything is up and running:</p> <pre><code>[bootc-user@localhost ~]$ systemctl status nginx postgresql\n</code></pre> <pre><code>\u25cf nginx.service - The nginx HTTP and reverse proxy server\n     Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; preset: disabled)\n     Active: active (running) since Mon 2024-07-29 12:31:03 CEST; 8min ago\n    Process: 727 ExecStartPre=/usr/bin/rm -f /run/nginx.pid (code=exited, status=0/SUCCESS)\n    Process: 730 ExecStartPre=/usr/sbin/nginx -t (code=exited, status=0/SUCCESS)\n    Process: 736 ExecStart=/usr/sbin/nginx (code=exited, status=0/SUCCESS)\n   Main PID: 749 (nginx)\n      Tasks: 3 (limit: 23136)\n     Memory: 4.2M\n        CPU: 11ms\n     CGroup: /system.slice/nginx.service\n             \u251c\u2500749 \"nginx: master process /usr/sbin/nginx\"\n             \u251c\u2500750 \"nginx: worker process\"\n             \u2514\u2500751 \"nginx: worker process\"\n\nJul 29 12:31:03 localhost.localdomain systemd[1]: Starting The nginx HTTP and reverse proxy server...\nJul 29 12:31:03 localhost.localdomain nginx[730]: nginx: the configuration file /etc/nginx/nginx.conf syntax is ok\nJul 29 12:31:03 localhost.localdomain nginx[730]: nginx: configuration file /etc/nginx/nginx.conf test is successful\nJul 29 12:31:03 localhost.localdomain systemd[1]: Started The nginx HTTP and reverse proxy server.\n\n\u25cf postgresql.service - PostgreSQL database server\n     Loaded: loaded (/usr/lib/systemd/system/postgresql.service; enabled; preset: disabled)\n     Active: active (running) since Mon 2024-07-29 12:39:52 CEST; 2s ago\n    Process: 1338 ExecStartPre=/usr/libexec/postgresql-check-db-dir postgresql (code=exited, status=0/SUCCESS)\n   Main PID: 1340 (postmaster)\n      Tasks: 8 (limit: 23136)\n     Memory: 16.5M\n        CPU: 16ms\n     CGroup: /system.slice/postgresql.service\n             \u251c\u25001340 /usr/bin/postmaster -D /var/lib/pgsql/data\n             \u251c\u25001341 \"postgres: logger \"\n             \u251c\u25001343 \"postgres: checkpointer \"\n             \u251c\u25001344 \"postgres: background writer \"\n             \u251c\u25001345 \"postgres: walwriter \"\n             \u251c\u25001346 \"postgres: autovacuum launcher \"\n             \u251c\u25001347 \"postgres: stats collector \"\n             \u2514\u25001348 \"postgres: logical replication launcher \"\n\nJul 29 12:39:52 localhost.localdomain systemd[1]: Starting PostgreSQL database server...\nJul 29 12:39:52 localhost.localdomain postmaster[1340]: 2024-07-29 12:39:52.234 CEST [1340] LOG:  redirecting log output to logging collector process\nJul 29 12:39:52 localhost.localdomain postmaster[1340]: 2024-07-29 12:39:52.234 CEST [1340] HINT:  Future log output will appear in directory \"log\".\nJul 29 12:39:52 localhost.localdomain systemd[1]: Started PostgreSQL database server.\n</code></pre> <p>Let's test if postgresql is working.</p> <pre><code>[bootc-user@localhost ~]$ sudo su -l postgres\nLast login: Mon Mar 18 10:34:34 CET 2024 on pts/0\n[postgres@localhost ~]$ psql\npsql (13.14)\nType \"help\" for help.\n\npostgres=#\n</code></pre> <p>Now we can try and see if the nginx server is reachable, using our browser we can go to the VM IP on port 80 to check:</p> <p></p> <p>Here we go, our VM is fully working. Of course we can use the new image to provision similar VMs that need the same pieces of software on them.</p>"},{"location":"use-cases/bootc-container-simple/","title":"Use Case - Simple RHEL bootc container","text":"<p>This example shows a very simple example of a bootc container the is built starting from a rhel-bootc image.</p> <p>The Containerfile in the example:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> </ul> Review Containerfile.simple <pre><code>LABEL org.opencontainers.image.authors=\"alerossi@redhat.com\"\nFROM registry.redhat.io/rhel10/rhel-bootc:10.1\nRUN dnf -y install tmux mkpasswd\nRUN pass=$(mkpasswd --method=SHA-512 --rounds=4096 redhat) &amp;&amp; useradd -m -G wheel bootc-user -p $pass\nRUN echo \"%wheel        ALL=(ALL)       NOPASSWD: ALL\" &gt; /etc/sudoers.d/wheel-sudo\n</code></pre>"},{"location":"use-cases/bootc-container-simple/#building-the-image","title":"Building the image","text":"<p>From the root folder of the repository, switch to the use case directory:</p> <pre><code>cd use-cases/bootc-container-simple\n</code></pre> <p>To build the image:</p> <pre><code>podman build -f Containerfile.simple -t rhel-bootc-simple .\n</code></pre> <p>You can now run it using:</p> <pre><code>podman run -it --name bootc-container --hostname bootc-container -p 2022:22 rhel-bootc-simple\n</code></pre> <p>Note: The \"-p 2022:22\" part forwards the container's SSH port to the host 2022 port.</p> <p>The container will now start and a login prompt will appear.</p> <p>You can simply login with bootc-user/redhat and play around with the container content!</p>"},{"location":"use-cases/bootc-container-update/","title":"Use Case - Updating a VM based on a bootc image","text":"<p>In this example, we want to add some bits to the previously generated httpd image to add a MariaDB server and a text editor, VIM.</p> <p>We will then use bootc to manage the system update, and you will see how easy and fast perfoming updates is.</p> <p>The Containerfile in this example will:</p> <ul> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs Apache Server</li> <li>Enables the systemd unit for httpd</li> <li>Adds a custom index.html</li> <li>Customizes the Message of the day</li> </ul> <p>But it will add the following two steps, resulting in a different image with an additional layer:</p> <p>- Add an additional message of the day with the update notes</p> <p>- Add mariadb-server package and vim</p> <p>- Enable the mariadb systemd unit</p> Review Containerfile.update <pre><code>LABEL org.opencontainers.image.authors=\"alerossi@redhat.com\"\nFROM registry.redhat.io/rhel9/rhel-bootc:9.7\nRUN dnf -y install tmux mkpasswd\nRUN pass=$(mkpasswd --method=SHA-512 --rounds=4096 redhat) &amp;&amp; useradd -m -G wheel bootc-user -p $pass\nRUN echo \"%wheel        ALL=(ALL)       NOPASSWD: ALL\" &gt; /etc/sudoers.d/wheel-sudo\nRUN dnf -y install httpd &amp;&amp; \\\n    systemctl enable httpd &amp;&amp; \\\n    mv /var/www /usr/share/www &amp;&amp; \\\n    sed -ie 's,/var/www,/usr/share/www,' /etc/httpd/conf/httpd.conf\nCOPY files/index.html /usr/share/www/html/index.html\nRUN echo \"This is a RHEL 9.7 VM installed using a bootable container as source!\" &gt; /etc/motd.d/10-first-setup.motd\nRUN echo \"This server now supports MariaDB as a database, after last update\" &gt; /etc/motd.d/20-upgrade.motd\nRUN dnf -y install mariadb mariadb-server vim &amp;&amp; dnf clean all &amp;&amp; rm -rf /var/cache /var/log/dnf &amp;&amp; systemctl enable mariadb\nCOPY ./files/00-mariadb-tmpfile.conf /usr/lib/tmpfiles.d/\nEXPOSE 80 3306\n</code></pre> <p>Since the bootc update command will preserve the /var and /etc content, we will use a workaround to create the needed dirs for MariaDB leveraging systemd tmpfiles:</p> <pre><code>d /var/lib/mysql 0755 mysql - 365d\nd /var/log/mariadb 0755 mysql - 365d\n</code></pre> <p>Since this is a minor update, not involving kernel modules or packages, we can leverage soft reboot to apply the changes.</p>"},{"location":"use-cases/bootc-container-update/#building-the-image","title":"Building the image","text":"<p>From the root folder of the repository, switch to the use case directory:</p> <pre><code>cd use-cases/bootc-container-update\n</code></pre> <p>You can build the image right from the Containerfile using Podman:</p> <pre><code>podman build -f Containerfile.update -t rhel-bootc-vm:httpd .\n</code></pre>"},{"location":"use-cases/bootc-container-update/#testing-the-image","title":"Testing the image","text":"<p>You can now test it using:</p> <pre><code>podman run -it --name rhel-bootc-vm --hostname rhel-bootc-vm -p 8080:80 -p 3306:3306 rhel-bootc-vm:httpd\n</code></pre> <p>Note: The \"-p 8080:80\" -p 3306:3306 part forwards the container's http and mariadb port to the port 8080 and 3306 on the host to test that httpd and mariadb are working.</p> <p>The container will now start and a login prompt will appear.</p>"},{"location":"use-cases/bootc-container-update/#testing-apache","title":"Testing Apache","text":"<p>On another terminal tab or in your browser, you can verify that the httpd server is working and serving traffic.</p> <p>Terminal</p> <pre><code> ~ curl localhost:8080\n</code></pre> <p>Browser</p> <p></p>"},{"location":"use-cases/bootc-container-update/#testing-mariadb","title":"Testing Mariadb","text":"<p>From the login prompt, login as bootc-user/redhat and impersonate the root user:</p> <pre><code>[bootc-user@rhel-bootc-vm ~]$ sudo -i\n[root@rhel-bootc-vm ~]#\n</code></pre> <p>Verify that mariadb is running:</p> <pre><code>mysql\n</code></pre>"},{"location":"use-cases/bootc-container-update/#tagging-and-pushing-the-image","title":"Tagging and pushing the image","text":"<p>To tag and push the image you can simply run (replace YOURQUAYUSERNAME with the account name):</p> <pre><code>export QUAY_USER=YOURQUAYUSERNAME\n</code></pre> <pre><code>podman tag rhel-bootc-vm:httpd quay.io/$QUAY_USER/rhel-bootc-vm:httpd\n</code></pre> <p>Log-in to Quay.io:</p> <pre><code>podman login -u $QUAY_USER quay.io\n</code></pre> <p>And push the image:</p> <pre><code>podman push quay.io/$QUAY_USER/rhel-bootc-vm:httpd\n</code></pre> <p>You can now browse to https://quay.io/repository/YOURQUAYUSERNAME/rhel-bootc-httpd?tab=settings and ensure that the repository is set to \"Public\".</p> <p></p>"},{"location":"use-cases/bootc-container-update/#updating-the-vm-with-the-newly-created-image","title":"Updating the VM with the newly created image","text":"<p>The first thing to do is logging in the VM created in the previous use case or any other use case (QCOW, ISO, AMI):</p> <pre><code> ~ \u2593\u2592\u2591 ssh bootc-user@192.168.124.16\nbootc-user@192.168.124.16's password:\nThis is a RHEL 10.0 VM installed using a bootable container as an rpm-ostree source!\nLast login: Mon Jul 29 12:03:40 2024 from 192.168.124.1\n[bootc-user@localhost ~]$\n</code></pre> <p>Verify that bootc is installed:</p> <pre><code>[bootc-user@localhost ~]$ bootc --help\nDeploy and transactionally in-place with bootable container images.\n\nThe `bootc` project currently uses ostree-containers as a backend to support a model of bootable container images.  Once installed, whether directly via `bootc install` (executed as part of a container) or via another mechanism such as an OS installer tool, further updates can be pulled via e.g. `bootc update`.\n\nChanges in `/etc` and `/var` persist.\n\nUsage: bootc &lt;COMMAND&gt;\n\nCommands:\n  update      Download and queue an updated container image to apply\n  switch       Target a new container image reference to boot\n  edit         Apply full changes to the host specification\n  status       Display status\n  usr-overlay  Add a transient writable overlayfs on `/usr` that will be discarded on reboot\n  install      Install the running container to a target\n  help         Print this message or the help of the given subcommand(s)\n\nOptions:\n  -h, --help   Print help (see a summary with '-h')\n</code></pre> <p>Note that among the options we have the update option that we will be using in this use case. The update option allows checking, fetching and using any updated container image corresponding to the imagename:tag we used, in this case quay.io/YOURQUAYUSERNAME/rhel-bootc-vm:httpd</p> <p>The update command requires higher privileges to run, let's perform the update!</p> <pre><code>[bootc-user@localhost ~]$ sudo bootc update --soft-reboot=required --apply\nlayers already present: 71; layers needed: 4 (99.3 MB)\n 379 B [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588] (0s) Fetched layer sha256:3851db6a0d50                                                                                                                                                                                                                                                                                                                                            Queued for next boot: quay.io/kubealex/rhel-bootc-vm:httpd\n  Version: 9.20251011.0\n  Digest: sha256:09ceaf9cc673ddd49ca204216433c688b09418e24992492b7f0e46ef27f4d5a5\nTotal new layers: 75    Size: 1.3 GB\nRemoved layers:   1     Size: 403 bytes\nAdded layers:     4     Size: 99.3 MB\n</code></pre> <p>As you can see, at the beginning it performs a comparison between the actual rpm-ostree image that the system is booted from and the new image, fetching only the additional layer corresponding to the updates introduced during the last build.</p> <p>As soft reboot restarts systemd services including sshd, we will be disconnected after the update is applied.</p> <p>Let's log back in!</p> <pre><code> ~ \u2593\u2592\u2591 ssh bootc-user@192.168.124.16\nbootc-user@192.168.124.16's password:\nThis is a RHEL 9 VM installed using a bootable container as source!\nThis server now supports MariaDB as a database, after last update\nLast login: Mon Jul 29 12:10:44 2024 from 192.168.124.1\n[bootc-user@localhost ~]$\n</code></pre> <p>You can already see that something changed, we have a new line in our message of the day, let's see if mariadb is running and test it using the default root user that is created by default (using sudo!):</p> <pre><code>[bootc-user@localhost ~]$ systemctl status mariadb\n\u25cf mariadb.service - MariaDB 10.5 database server\n     Loaded: loaded (/usr/lib/systemd/system/mariadb.service; enabled; preset: disabled)\n     Active: active (running) since Mon 2024-07-29 12:12:27 CEST; 44s ago\n       Docs: man:mariadbd(8)\n             https://mariadb.com/kb/en/library/systemd/\n    Process: 676 ExecStartPre=/usr/libexec/mariadb-check-socket (code=exited, status=0/SUCCESS)\n    Process: 722 ExecStartPre=/usr/libexec/mariadb-prepare-db-dir mariadb.service (code=exited, status=0/SUCCESS)\n    Process: 1373 ExecStartPost=/usr/libexec/mariadb-check-update (code=exited, status=0/SUCCESS)\n   Main PID: 1359 (mariadbd)\n     Status: \"Taking your SQL requests now...\"\n      Tasks: 13 (limit: 23136)\n     Memory: 97.1M\n        CPU: 195ms\n     CGroup: /system.slice/mariadb.service\n             \u2514\u25001359 /usr/libexec/mariadbd --basedir=/usr\n\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: The second is mysql@localhost, it has no password either, but\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: you need to be the system 'mysql' user to connect.\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: After connecting you can set the password, if you would need to be\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: able to connect as any of these users with a password and without sudo\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: See the MariaDB Knowledgebase at https://mariadb.com/kb\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: Please report any problems at https://mariadb.org/jira\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: The latest information about MariaDB is available at https://mariadb.org/.\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: Consider joining MariaDB's strong and vibrant community:\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: https://mariadb.org/get-involved/\nJul 29 12:12:27 localhost.localdomain systemd[1]: Started MariaDB 10.5 database server.\n</code></pre> <pre><code>[bootc-user@localhost ~]$ sudo mysql\nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MariaDB connection id is 3\nServer version: 10.5.22-MariaDB MariaDB Server\n\nCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nMariaDB [(none)]&gt;\n</code></pre> <p>Here we go, our image is updated and fully working. Of course we can use the new image to provision similar VMs that need the same pieces of software on them.</p>"},{"location":"use-cases/bootc-container-upgrade/","title":"Use Case - Upgrading a VM based on a bootc image","text":"<p>In this example, we want to add some bits to the previously generated httpd image to upgrade the system from RHEL 9.7 to RHEL 10.1.</p> <p>We will then use bootc to manage the system upgrade, and you will see how easy and fast perfoming upgrades is.</p> <p>The Containerfile in this example will:</p> <ul> <li>Customize the index file</li> <li>Customizes the Message of the day</li> </ul> Review Containerfile.upgrade <pre><code>FROM registry.redhat.io/rhel10/rhel-bootc:10.1\nRUN dnf -y install tmux mkpasswd\nRUN pass=$(mkpasswd --method=SHA-512 --rounds=4096 redhat) &amp;&amp; useradd -m -G wheel bootc-user -p $pass\nRUN echo \"%wheel        ALL=(ALL)       NOPASSWD: ALL\" &gt; /etc/sudoers.d/wheel-sudo\nRUN dnf -y install httpd &amp;&amp; \\\n    systemctl enable httpd &amp;&amp; \\\n    mv /var/www /usr/share/www &amp;&amp; \\\n    sed -ie 's,/var/www,/usr/share/www,' /etc/httpd/conf/httpd.conf &amp;&amp; \\\n    mkdir -p /var/log/httpd\nCOPY files/index.html /usr/share/www/html/index.html\nRUN echo \"This is a RHEL 10.1 VM installed using a bootable container as source!\" &gt; /etc/motd.d/10-first-setup.motd\nRUN echo \"This server is now running on RHEL 10 after the latest upgrade.\" &gt; /etc/motd.d/20-upgrade.motd\nEXPOSE 80\n</code></pre>"},{"location":"use-cases/bootc-container-upgrade/#building-the-image","title":"Building the image","text":"<p>From the root folder of the repository, switch to the use case directory:</p> <pre><code>cd use-cases/bootc-container-upgrade\n</code></pre> <p>You can build the image right from the Containerfile using Podman:</p> <pre><code>podman build -f Containerfile.upgrade -t rhel-bootc-vm:httpd .\n</code></pre>"},{"location":"use-cases/bootc-container-upgrade/#testing-the-image","title":"Testing the image","text":"<p>You can now test it using:</p> <pre><code>podman run -it --name rhel-bootc-vm --hostname rhel-bootc-vm -p 8080:80 rhel-bootc-vm:httpd\n</code></pre> <p>Note: The \"-p 8080:80\" part forwards the container's http port to the port 8080 on the host to test that httpd is working.</p> <p>The container will now start and a login prompt will appear.</p>"},{"location":"use-cases/bootc-container-upgrade/#testing-apache","title":"Testing Apache","text":"<p>On another terminal tab or in your browser, you can verify that the httpd server is working and serving traffic.</p> <p>Terminal</p> <pre><code> ~ curl localhost:8080\n</code></pre> <p>Browser</p> <p></p>"},{"location":"use-cases/bootc-container-upgrade/#tagging-and-pushing-the-image","title":"Tagging and pushing the image","text":"<p>To tag and push the image you can simply run (replace YOURQUAYUSERNAME with the account name):</p> <pre><code>export QUAY_USER=YOURQUAYUSERNAME\n</code></pre> <pre><code>podman tag rhel-bootc-vm:httpd quay.io/$QUAY_USER/rhel-bootc-vm:httpd\n</code></pre> <p>Log-in to Quay.io:</p> <pre><code>podman login -u $QUAY_USER quay.io\n</code></pre> <p>And push the image:</p> <pre><code>podman push quay.io/$QUAY_USER/rhel-bootc-vm:httpd\n</code></pre> <p>You can now browse to https://quay.io/repository/YOURQUAYUSERNAME/rhel-bootc-httpd?tab=settings and ensure that the repository is set to \"Public\".</p> <p></p>"},{"location":"use-cases/bootc-container-upgrade/#updating-the-vm-with-the-newly-created-image","title":"Updating the VM with the newly created image","text":"<p>The first thing to do is logging in the VM created in the previous use case or any other use case (QCOW, ISO, AMI):</p> <pre><code> ~ \u2593\u2592\u2591 ssh bootc-user@192.168.124.16\nbootc-user@192.168.124.16's password:\nThis is a RHEL 9.7 VM installed using a bootable container as an rpm-ostree source!\nLast login: Mon Jul 29 12:03:40 2024 from 192.168.124.1\n[bootc-user@localhost ~]$\n</code></pre> <p>Verify that bootc is installed:</p> <pre><code>[bootc-user@localhost ~]$ bootc --help\nDeploy and transactionally in-place with bootable container images.\n\nThe `bootc` project currently uses ostree-containers as a backend to support a model of bootable container images.  Once installed, whether directly via `bootc install` (executed as part of a container) or via another mechanism such as an OS installer tool, further upgrades can be pulled via e.g. `bootc upgrade`.\n\nChanges in `/etc` and `/var` persist.\n\nUsage: bootc &lt;COMMAND&gt;\n\nCommands:\n  upgrade      Download and queue an upgraded container image to apply\n  switch       Target a new container image reference to boot\n  edit         Apply full changes to the host specification\n  status       Display status\n  usr-overlay  Add a transient writable overlayfs on `/usr` that will be discarded on reboot\n  install      Install the running container to a target\n  help         Print this message or the help of the given subcommand(s)\n\nOptions:\n  -h, --help   Print help (see a summary with '-h')\n</code></pre> <p>Note that among the options we have the upgrade option that we will be using in this use case. The upgrade option allows checking, fetching and using any upgraded container image corresponding to the imagename:tag we used, in this case quay.io/YOURQUAYUSERNAME/rhel-bootc-vm:httpd</p> <p>The upgrade command requires higher privileges to run, let's perform the upgrade!</p> <pre><code>[bootc-user@localhost ~]$ sudo bootc upgrade\nlayers already present: 2; layers needed: 71 (1.5 GB)\nFetching layers \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 71/71\n \u2514 Fetching \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 240 B/240 B (0 B/s) layer 3f31bbba8d765173de253\nFetched layers: 1.39 GiB in 3 minutes (6.93 MiB/\nQueued for next boot: quay.io/kubealex/rhel-image-mode-demo:app\n  Version: 10.20250116.0\n  Digest: sha256:4cf5180c3586eaf352661e05399ff23a9a2e021a98acefaabd83b0e991dd21b3\nTotal new layers: 73    Size: 1.5 GB\nRemoved layers:   78    Size: 1.5 GB\nAdded layers:     71    Size: 1.5 GB\n</code></pre> <p>As you can see, at the beginning it performs a comparison between the actual rpm-ostree image that the system is booted from and the new image, fetching only the additional layer corresponding to the upgrades introduced during the last build.</p> <p>Proceed with a reboot:</p> <pre><code>[bootc-user@localhost ~]$ sudo reboot\n</code></pre> <p>Let's log back in!</p> <pre><code> ~ \u2593\u2592\u2591 ssh bootc-user@192.168.122.19\nbootc-user@192.168.122.19's password:\nThis is a RHEL 10.1 VM installed using a bootable container as source!\nThis server is now running on RHEL 10 after the latest upgrade.\nLast login: Mon Feb 24 12:15:42 2025 from 192.168.122.1\n[bootc-user@localhost ~]$\n</code></pre> <p>You can already see that something changed, we have a new line in our message of the day, let's check the OS version:</p> <pre><code>[bootc-user@localhost ~]$ cat /etc/os-release\nNAME=\"Red Hat Enterprise Linux\"\nVERSION=\"10.1 (Coughlan)\"\nID=\"rhel\"\nID_LIKE=\"centos fedora\"\nVERSION_ID=\"10.1\"\nPLATFORM_ID=\"platform:el10\"\nPRETTY_NAME=\"Red Hat Enterprise Linux 10.1 (Coughlan)\"\nANSI_COLOR=\"0;31\"\nLOGO=\"fedora-logo-icon\"\nCPE_NAME=\"cpe:/o:redhat:enterprise_linux:10::baseos\"\nHOME_URL=\"https://www.redhat.com/\"\nVENDOR_NAME=\"Red Hat\"\nVENDOR_URL=\"https://www.redhat.com/\"\nDOCUMENTATION_URL=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/10\"\nBUG_REPORT_URL=\"https://issues.redhat.com/\"\n\nREDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 10\"\nREDHAT_BUGZILLA_PRODUCT_VERSION=10.1\nREDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\"\nREDHAT_SUPPORT_PRODUCT_VERSION=\"10.1\"\n</code></pre> <p>Here we go, our image is upgraded and fully working. Of course we can use the new image to provision similar VMs that need the same pieces of software on them.</p>"},{"location":"use-cases/bootc-image-builder-ami/","title":"Use Case - Building a RHEL AWS AMI image using bootc-image-builder","text":"<p>Warning</p> <p>This example requires an active AWS account. Free tier could not be enough due to the 5GB limitation on S3 storage.</p> <p>In this example, we will build a container image from a Containerfile and we will generate an AWS AMI to use as a base for Instances.</p> <p>The Containerfile in the example:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs Apache Server</li> <li>Enables the systemd unit for httpd</li> <li>Adds a custom index.html</li> </ul> Review Containerfile.ami <pre><code>LABEL org.opencontainers.image.authors=\"alerossi@redhat.com\"\nFROM registry.redhat.io/rhel10/rhel-bootc:10.1\nRUN dnf -y install tmux mkpasswd\nRUN pass=$(mkpasswd --method=SHA-512 --rounds=4096 redhat) &amp;&amp; useradd -m -G wheel bootc-user -p $pass\nRUN echo \"%wheel        ALL=(ALL)       NOPASSWD: ALL\" &gt; /etc/sudoers.d/wheel-sudo\nRUN dnf -y install httpd &amp;&amp; \\\n    systemctl enable httpd &amp;&amp; \\\n    mv /var/www /usr/share/www &amp;&amp; \\\n    sed -ie 's,/var/www,/usr/share/www,' /etc/httpd/conf/httpd.conf\nRUN echo \"Welcome to the bootc-http instance!\" &gt; /usr/share/www/html/index.html\nEXPOSE 80\n</code></pre>"},{"location":"use-cases/bootc-image-builder-ami/#building-the-image","title":"Building the image","text":"<p>From the root folder of the repository, switch to the use case directory:</p> <pre><code>cd use-cases/bootc-image-builder-ami\n</code></pre> <p>To build the image:</p> <pre><code>podman build -f Containerfile.ami -t rhel-bootc-vm:ami .\n</code></pre>"},{"location":"use-cases/bootc-image-builder-ami/#testing-the-image","title":"Testing the image","text":"<p>You can now test it using:</p> <pre><code>podman run -it --name rhel-bootc-vm --hostname rhel-bootc-vm -p 8080:80 rhel-bootc-vm:ami\n</code></pre> <p>Note: The \"-p 8080:80\" part forwards the container's http port to the port 8080 on the host to test that it is working.</p> <p>The container will now start and a login prompt will appear.</p> <p>On another terminal tab or in your browser, you can verify that the httpd server is working and serving traffic.</p> <p>Terminal</p> <pre><code> ~ \u2593\u2592\u2591 curl localhost:8080\nWelcome to the bootc-http instance!\n</code></pre> <p>Browser</p> <p></p>"},{"location":"use-cases/bootc-image-builder-ami/#tagging-and-pushing-the-image","title":"Tagging and pushing the image","text":"<p>To tag and push the image you can simply run (replace YOURQUAYUSERNAME with the account name):</p> <pre><code>export QUAY_USER=YOURQUAYUSERNAME\n</code></pre> <pre><code>podman tag rhel-bootc-vm:ami quay.io/$QUAY_USER/rhel-bootc-vm:ami\n</code></pre> <p>Log-in to Quay.io:</p> <pre><code>podman login -u $QUAY_USER quay.io\n</code></pre> <p>And push the image:</p> <pre><code>podman push quay.io/$QUAY_USER/rhel-bootc-vm:ami\n</code></pre> <p>You can now browse to https://quay.io/repository/YOURQUAYUSERNAME/rhel-bootc-vm?tab=settings and ensure that the repository is set to \"Public\".</p> <p></p>"},{"location":"use-cases/bootc-image-builder-ami/#configure-required-resources-for-aws","title":"Configure required resources for AWS","text":"<p>The AMI building process will need some configuration both on the client (for CLI configuration and credentials) and on AWS (for resources and IAM).</p> <p>The specific needs are:</p> <ul> <li>an S3 bucket to temporarily store the AMI image that will be imported in the catalog</li> <li>a policy (vmimport) to allow importing from S3 to the AMI catalog</li> <li>a role to allow the vmie service and bind the policy</li> </ul> <p>In the files folder are stored the policy definition and the role definition that you can review below before applying.</p> Review aws-policy.json <pre><code>{\n    \"Version\":\"2012-10-17\",\n    \"Statement\":[\n       {\n          \"Effect\": \"Allow\",\n          \"Action\": [\n             \"s3:GetBucketLocation\",\n             \"s3:GetObject\",\n             \"s3:ListBucket\" \n          ],\n          \"Resource\": [\n             \"arn:aws:s3:::rhel-bootc-demo\",\n             \"arn:aws:s3:::rhel-bootc-demo/*\"\n          ]\n       },\n       {\n          \"Effect\": \"Allow\",\n          \"Action\": [\n             \"ec2:ModifySnapshotAttribute\",\n             \"ec2:CopySnapshot\",\n             \"ec2:RegisterImage\",\n             \"ec2:Describe*\"\n          ],\n          \"Resource\": \"*\"\n       }\n    ]\n }\n</code></pre> Review aws-role.json <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n       {\n          \"Effect\": \"Allow\",\n          \"Principal\": { \n            \"Service\": \"vmie.amazonaws.com\" \n        },\n          \"Action\": \"sts:AssumeRole\",\n          \"Condition\": {\n             \"StringEquals\":{\n                \"sts:Externalid\": \"vmimport\"\n             }\n          }\n       }\n    ]\n }\n</code></pre> <p>To start the configuration use the aws configure command and provide the required information:</p> <pre><code>[~]$ aws configure\nAWS Access Key ID []:\nAWS Secret Access Key []:\nDefault region name []:\nDefault output format [json]:\n</code></pre> <p>Once this is in place, we can proceed with the resources.</p> <p>For S3 (replace YOURREGION with the correct region, ie. eu-west-1):</p> <p>Tip</p> <p>S3 Bucket names are globally registered and unique, based on the name you find available, edit the reference in lines 12-13 of the aws-policy.json file</p> <pre><code>[~]$ export REGION=YOURREGION\naws s3api create-bucket --bucket rhel-bootc-demo --create-bucket-configuration LocationConstraint=$REGION\n</code></pre> <p>Let's proceed with the role:</p> <pre><code>aws iam create-role --role-name vmimport --assume-role-policy-document file://files/aws-role.json\n</code></pre> <p>And then associate the policy to the role:</p> <pre><code>aws iam put-role-policy --role-name vmimport --policy-name vmimport --policy-document file://files/aws-policy.json\n</code></pre> <p>We are now good to go!</p>"},{"location":"use-cases/bootc-image-builder-ami/#generating-the-aws-ami-image","title":"Generating the AWS AMI image","text":"<p>To generate the AMI image we will be using bootc-image-builder container image that will help us transitioning from our newly generated bootable container image to an AMI image that can be used on AWS.</p> <p>Let's proceed with the QCOW image creation:</p> <pre><code>sudo podman run \\\n    --rm \\\n    -it \\\n    --privileged \\\n    --pull=newer \\\n    -v $HOME/.aws:/root/.aws:ro \\\n    --env AWS_PROFILE=default \\\n    registry.redhat.io/rhel10/bootc-image-builder:latest \\\n    build \\\n    --type ami \\\n    --aws-ami-name rhel-bootc-x86 \\\n    --aws-bucket rhel-bootc-demo \\\n    --aws-region eu-west-1 \\\n    quay.io/$QUAY_USER/rhel-bootc-vm:ami\n</code></pre> <p>The process will take care of all required steps (deploying the image, SELinux configuration, filesystem configuration, ostree configuration, etc.), after a couple of minutes we will find in the output:</p> <pre><code>Building manifest-ami.json\nstarting -Pipeline source org.osbuild.containers-storage: 6ec72d5cb7fb74985ee0fcdc8d90db85079cd08caa64fde9153c40aae3744f18\nBuild\n  root: &lt;host&gt;\nPipeline build: 733863e98e5497425dbf00ac2eec52175d453834f17868944ed3408bcd9a3d16\nBuild\n  root: &lt;host&gt;\n  runner: org.osbuild.rhel82 (org.osbuild.rhel82)\n[...]\n\n\u23f1  Duration: 1s\nmanifest - finished successfully\nbuild:          733863e98e5497425dbf00ac2eec52175d453834f17868944ed3408bcd9a3d16\nimage:          6b2f313ea4e75ddb9f8c9f2da14d4234760986240d1957093bb3631f0010c09e\nqcow2:          194f4993f08ada94b56bc5a59d17a08251388f9210e13f4671d231f7cd9abb97\nvmdk:           6d03b4759af85fd6408f36c72fde3eaa271466beef14a5f1af0499410055df9c\novf:            c2410b0f4eecb91c7298d17c98dc672b42aedd02bb9809dab8feb1b185259689\narchive:        950f23c305d2b41148790246e9abb8c925da34077f2954fabad284b9782f914e\nBuild complete!\nUploading image/disk.raw to rhel-bootc-demo:b1a83f25-051e-434c-a50f-ab634d1b798c-disk.raw\n10.00 GiB / 10.00 GiB [------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------] 100.00% 79.03 MiB p/s\nFile uploaded to https://rhel-bootc-demo.s3.eu-west-1.amazonaws.com/b1a83f25-051e-434c-a50f-ab634d1b798c-disk.raw\nRegistering AMI rhel-bootc-x86\nDeleted S3 object rhel-bootc-demo:b1a83f25-051e-434c-a50f-ab634d1b798c-disk.raw\nAMI registered: ami-0ade40e197a89bb69\nSnapshot ID: snap-068821f35b9b832af\n</code></pre> <p>You can verify that the AMI is now present in the AMIs section on AWS. (the URL may be different based on the region).</p> <p></p>"},{"location":"use-cases/bootc-image-builder-ami/#create-the-instance-on-aws","title":"Create the Instance on AWS","text":"<p>Using your preferred method, either via GUI or CLI, you can now create a fresh instance using the AMI we just imported.</p> <p>Wait for the Instance to be ready and retrieve the IP address to log-in using SSH using bootc-user/redhat credentials:</p> <pre><code> ~ \u2593\u2592\u2591\n\u276f ssh bootc-user@*****\n\nThe authenticity of host '***** (*****)' can't be established.\nED25519 key fingerprint is SHA256:OgY5Ym9dycIE2KPS5SRYRcmogUHalrUD35CyEH2A/j4.\nThis key is not known by any other names.\nAre you sure you want to continue connecting (yes/no/[fingerprint])? yes\nWarning: Permanently added '*****' (ED25519) to the list of known hosts.\nbootc-user@*****'s password:\n[bootc-user@ip-172-31-22-31 ~]$\n</code></pre>"},{"location":"use-cases/bootc-image-builder-iso/","title":"Use Case - Building a RHEL ISO image using bootc-image-builder","text":"<p>In this example, we will build a container image from a Containerfile and we will generate a ISO image to spin up a Virtual Machine in KVM and install RHEL from the container image.</p> <p>The Containerfile in the example:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs Apache Server</li> <li>Enables the systemd unit for httpd</li> <li>Adds a custom index.html</li> </ul> Review Containerfile.iso <pre><code>LABEL org.opencontainers.image.authors=\"alerossi@redhat.com\"\nFROM registry.redhat.io/rhel10/rhel-bootc:10.1\nRUN dnf -y install tmux mkpasswd\nRUN echo \"%wheel        ALL=(ALL)       NOPASSWD: ALL\" &gt; /etc/sudoers.d/wheel-sudo\nRUN dnf -y install httpd &amp;&amp; \\\n    systemctl enable httpd &amp;&amp; \\\n    mv /var/www /usr/share/www &amp;&amp; \\\n    sed -ie 's,/var/www,/usr/share/www,' /etc/httpd/conf/httpd.conf\nRUN echo \"Welcome to the bootc-http instance!\" &gt; /usr/share/www/html/index.html\nEXPOSE 80\n</code></pre>"},{"location":"use-cases/bootc-image-builder-iso/#building-the-image","title":"Building the image","text":"<p>From the root folder of the repository, switch to the use case directory:</p> <pre><code>cd use-cases/bootc-image-builder-iso\n</code></pre> <p>To build the image:</p> <pre><code>podman build -f Containerfile.iso -t rhel-bootc-vm:iso\n</code></pre>"},{"location":"use-cases/bootc-image-builder-iso/#testing-the-image","title":"Testing the image","text":"<p>You can now test it using:</p> <pre><code>podman run -it --rm --name rhel-bootc-vm --hostname rhel-bootc-vm -p 8080:80 rhel-bootc-vm:iso\n</code></pre> <p>Note: The \"-p 8080:80\" part forwards the container's http port to the port 8080 on the host to test that it is working.</p> <p>The container will now start and a login prompt will appear.</p> <p>On another terminal tab or in your browser, you can verify that the httpd server is working and serving traffic.</p> <p>Terminal</p> <p><pre><code>curl localhost:8080\n</code></pre> <pre><code>Welcome to the bootc-http instance!\n</code></pre></p> <p>Browser</p> <p></p> <p>Stop the httpd server from the second container using podman.</p> <pre><code>podman stop rhel-bootc-vm\n</code></pre>"},{"location":"use-cases/bootc-image-builder-iso/#tagging-and-pushing-the-image","title":"Tagging and pushing the image","text":"<p>To tag and push the image you can simply run (replace YOURQUAYUSERNAME with the account name):</p> <pre><code>export QUAY_USER=YOURQUAYUSERNAME\n</code></pre> <pre><code>podman tag rhel-bootc-vm:iso quay.io/$QUAY_USER/rhel-bootc-vm:iso\n</code></pre> <p>Log-in to Quay.io:</p> <pre><code>podman login -u $QUAY_USER quay.io\n</code></pre> <p>And push the image:</p> <pre><code>podman push quay.io/$QUAY_USER/rhel-bootc-vm:iso\n</code></pre>"},{"location":"use-cases/bootc-image-builder-iso/#customize-the-image","title":"Customize the image","text":"<p>In this example, we will not create the user in the image, but we will provide a customization using the config.toml file. It can be used to perform customizations of users, groups, etc.</p> <p>A sample config.toml is already present in the use case directory, that we will use to create our VM. As this is an install ISO, we use kickstart to create the VM as well as the  bootc-user/redhat and add it to the wheel group is as follows:</p> <pre><code>  [customizations.installer.kickstart]\n  contents = \"\"\"\n  # Basic setup\n\n  network --bootproto=dhcp --device=link --activate \n\n  # Basic partitioning\n  clearpart --all --initlabel --disklabel=gpt\n  reqpart --add-boot\n  part / --grow --fstype xfs\n\n  # No ostreecontainer command needed, instead we lay down the container contents with BIB in the ISO\n\n  firewall --disabled\n  services --enabled=sshd\n\n  # mkpasswd --method=SHA-512 --rounds=4096 redhat\n  user --name=bootc-user --groups=wheel --iscrypted --password=$6$rounds=4096$1VjdHWc6vFCglSh9$3HcKRPO8i2ias09AJ9y6FhQu4V/es/evh6/GJtTtduV.K6AExr.eQb/Ava8v0fZhHKTtoFniEGR2nKO.fCear1\n\n  # Only inject a SSH key for root\n  rootpw --iscrypted locked\n\n  reboot\n  \"\"\"\n</code></pre>"},{"location":"use-cases/bootc-image-builder-iso/#generating-the-iso-image","title":"Generating the ISO image","text":"<p>To generate the ISO image we will be using bootc-image-builder container image that will help us transitioning from our newly generated bootable container image to a ISO file that can be used with KVM or bare metal to install the OS.</p> <p>The bootc-image-builder container will need rootful access to run and a local copy of the image in system storage. You can pull the image using <code>root</code> credentials from quay.io to accomplish this. If the repository isn't public, you will need to log into quay.io again. You can control visibility of the repository under <code>Repository Settings</code> in the quay.io interface.</p> <pre><code>sudo podman login -u $QUAY_USER quay.io\nsudo podman pull quay.io/$QUAY_USER/rhel-bootc-vm:iso\n</code></pre> Using podman image scp <p>You can use <code>podman</code> to copy images between remote hosts using SCP with the <code>image</code> subcommand. This will also work for local storage on Linux without using SSHd. For example, to copy the locally built image to system storage without pulling from the quay.io:</p> <pre><code>podman image scp quay.io/$QUAY_USER/rhel-bootc-vm:iso root@localhost::\n</code></pre> <p>Once the image has been made available, proceed with the ISO image creation:</p> <pre><code>sudo podman run \\\n    --rm \\\n    --privileged \\\n    --security-opt label=type:unconfined_t \\\n    -v $(pwd)/output:/output \\\n    -v $(pwd)/config.toml:/config.toml \\\n    -v /var/lib/containers/storage:/var/lib/containers/storage \\\n    registry.redhat.io/rhel10/bootc-image-builder:latest \\\n    --type iso \\\n    quay.io/$QUAY_USER/rhel-bootc-vm:iso\n</code></pre> <p>We will use the image we built to create our ISO in the output folder.</p> <p>The process will take care of all required steps (deploying the image, SELinux configuration, filesystem configuration, ostree configuration, etc.), after a couple of minutes we will find in the output:</p> <pre><code>Generating manifest manifest-iso.json\nDONE\nBuilding manifest-iso.json\nstarting -Pipeline source org.osbuild.containers-storage: f1027594ecbee0b434f86af01d4ba21b478265c0c773e35c387858d0fc4bf16d\nBuild\n  root: &lt;host&gt;\nPipeline source org.osbuild.curl: 07337b98b3c859adfb37b011d83cf0511884147bf999e7869ffbf9074b529a4f\nBuild\n  root: &lt;host&gt;\n[...]\n\n\u23f1  Duration: 9s\norg.osbuild.implantisomd5: 3798a4bfccd982e2e24d6130c4174eba98ad12f94a41b25ec8884a8cfccaf8ce {\n  \"filename\": \"install.iso\"\n}\n['implantisomd5', '/run/osbuild/tree/install.iso']\nInserting md5sum into iso image...\nmd5 = 66adac8cb9127c31942085bade81a8d4\nInserting fragment md5sums into iso image...\nfragmd5 = 9d5d936a1b5c8f9bf96e1e14c164898d8e2fcf45652dbee6f3741e17b5ca\nfrags = 20\nSetting supported flag to 0\n\n\u23f1  Duration: 6s\nmanifest - finished successfully\nbuild:          9133fb8610ab053dae7e281e6a6655dbb912c4530d32e4da75c06b8713a87c80\nanaconda-tree:  fcd61d1236a42900977530f12f45fe452f2f0c8bf3c80a7ba60cb45ffe4bf36d\nrootfs-image:   0a517e05ab42f947beec8dae4d2da338ca9cc7fe17b1daba013e24b1c60aeadf\nefiboot-tree:   61a20c820b40436ce7bd6d1a74c6b97a05f7c8800b678083942e814cf9f7cc0e\nbootiso-tree:   fd0185a1c0eb53df152acd85195c016315e79dd5dc32eb32d07abf0e21251c62\nbootiso:        3798a4bfccd982e2e24d6130c4174eba98ad12f94a41b25ec8884a8cfccaf8ce\nBuild complete!\nResults saved in\n</code></pre> <p>Verify that under the output/bootiso folder we have our image ready to be used.</p> <p><pre><code>tree output\n</code></pre> <pre><code>output/\n\u251c\u2500\u2500 bootiso\n\u2502   \u2514\u2500\u2500 install.iso\n\u2514\u2500\u2500 manifest-iso.json\n\n2 directories, 2 files\n</code></pre></p>"},{"location":"use-cases/bootc-image-builder-iso/#create-the-vm-in-kvm","title":"Create the VM in KVM","text":"<p>We will now use the image to spin up our Virtual Machine in KVM. Copy the ISO to a KVM storage pool on the system. We'll use a standard libvirt location, <code>boot</code> but if you have another storage pool configured you can use that as well.</p> <pre><code>sudo cp output/bootiso/install.iso /var/lib/libvirt/boot/\n</code></pre> <pre><code>sudo virt-install \\\n    --name rhel-bootc-vm \\\n    --vcpus 4 \\\n    --memory 4096 \\\n    --cdrom /var/lib/libvirt/boot/install.iso \\\n    --os-variant rhel10-unknown \\\n    --disk size=20 \\\n    --network network=default\n</code></pre> <p>We can check that the installer is running using the VM Console:</p> <p></p> <p>You can log into the graphical console directly, or log in via SSH in another shell. Wait for the VM to be ready and retrieve the IP address for the domain to log-in using SSH using bootc-user/redhat credentials:</p> <p><pre><code>VM_IP=$(sudo virsh -q domifaddr rhel-bootc-vm | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\n</code></pre> <pre><code>Warning: Permanently added '192.168.124.209' (ED25519) to the list of known hosts.\nbootc-user@192.168.124.209's password:\nThis is a RHEL 10.0 VM installed using a bootable container as an rpm-ostree source!\n[bootc-user@localhost ~]$\n</code></pre></p>"},{"location":"use-cases/bootc-image-builder-qcow/","title":"Use Case - Building a RHEL QCOW image using bootc-image-builder","text":"<p>In this example, we will build a container image from a Containerfile and we will generate a QCOW image to spin up a Virtual Machine in KVM.</p> <p>The Containerfile in the example:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs Apache Server</li> <li>Enables the systemd unit for httpd</li> <li>Adds a custom index.html</li> </ul> Review Containerfile.qcow <pre><code>LABEL org.opencontainers.image.authors=\"alerossi@redhat.com\"\nFROM registry.redhat.io/rhel10/rhel-bootc:10.1\nRUN dnf -y install tmux mkpasswd\nRUN pass=$(mkpasswd --method=SHA-512 --rounds=4096 redhat) &amp;&amp; useradd -m -G wheel bootc-user -p $pass\nRUN echo \"%wheel        ALL=(ALL)       NOPASSWD: ALL\" &gt; /etc/sudoers.d/wheel-sudo\nRUN dnf -y install httpd &amp;&amp; \\\n    systemctl enable httpd &amp;&amp; \\\n    mv /var/www /usr/share/www &amp;&amp; \\\n    sed -ie 's,/var/www,/usr/share/www,' /etc/httpd/conf/httpd.conf\nCOPY files/index.html /usr/share/www/html/index.html\nEXPOSE 80\n</code></pre>"},{"location":"use-cases/bootc-image-builder-qcow/#building-the-image","title":"Building the image","text":"<p>From the root folder of the repository, switch to the use case directory:</p> <pre><code>cd use-cases/bootc-image-builder-qcow\n</code></pre> <p>To build the image:</p> <pre><code>podman build -f Containerfile.qcow -t rhel-bootc-vm:qcow .\n</code></pre>"},{"location":"use-cases/bootc-image-builder-qcow/#testing-the-image","title":"Testing the image","text":"<p>You can now test it using:</p> <pre><code>podman run -it --name rhel-bootc-vm --hostname rhel-bootc-vm -p 8080:80 rhel-bootc-vm:qcow\n</code></pre> <p>Note: The \"-p 8080:80\" part forwards the container's http port to the port 8080 on the host to test that it is working.</p> <p>The container will now start and a login prompt will appear.</p> <p>On another terminal tab or in your browser, you can verify that the httpd server is working and serving traffic.</p> <p>Terminal</p> <pre><code> ~ \u2593\u2592\u2591 curl localhost:8080\nWelcome to the bootc-http instance!\n</code></pre> <p>Browser</p> <p></p>"},{"location":"use-cases/bootc-image-builder-qcow/#generating-the-qcow-image","title":"Generating the QCOW image","text":"<p>To generate the QCOW image we will be using bootc-image-builder container image that will help us transitioning from our newly generated bootable container image to a VM image that can be used with KVM.</p> <p>The bootc-image-builder container will need rootful access to run, so the first thing we need to do is copying the image from our current user (the one we built the image with) to root:</p> <pre><code>podman image scp $(whoami)@localhost::rhel-bootc-vm:qcow\n</code></pre> <p>Now, verify that the image is correctly present for root user:</p> <pre><code> ~ \u2593\u2592\u2591 sudo podman images\nREPOSITORY                                TAG         IMAGE ID      CREATED        SIZE\nlocalhost/rhel-bootc-vm                 qcow        0ee1017eb9bc  7 minutes ago  1.81 GB\n</code></pre> <p>We are now ready! Let's proceed with the QCOW image creation:</p> <pre><code>sudo podman run \\\n    --rm \\\n    -it \\\n    --privileged \\\n    --pull=newer \\\n    --security-opt label=type:unconfined_t \\\n    -v $(pwd)/output:/output \\\n    -v /var/lib/containers/storage:/var/lib/containers/storage \\\n    registry.redhat.io/rhel10/bootc-image-builder:latest \\\n    build \\\n    --type qcow2 \\\n    --local \\\n    localhost/rhel-bootc-vm:qcow\n</code></pre> <p>We will use the local image we just copied to save in the output folder our generated image.</p> <p>The process will take care of all required steps (deploying the image, SELinux configuration, filesystem configuration, ostree configuration, etc.), after a couple of minutes we will find in the output:</p> <pre><code>Generating manifest-qcow2.json ... DONE\nBuilding manifest-qcow2.json\nstarting -Pipeline source org.osbuild.containers-storage: 8aaabad5f0c2c00eb12666076be4e6843f04e262230e2976dbb1218e96f2ca53\nBuild\n  root: &lt;host&gt;\nPipeline build: 2fb8b2a9ec9dc564950ddc6213d923bdd036c2328a97d0bb785c72fb5b6e1154\nBuild\n  root: &lt;host&gt;\n  runner: org.osbuild.rhel82 (org.osbuild.rhel82)\n[...]\n\n\u23f1  Duration: 81s\nmanifest - finished successfully\nbuild:          2fb8b2a9ec9dc564950ddc6213d923bdd036c2328a97d0bb785c72fb5b6e1154\nimage:          a578f97344212ef8cdc1a53717b61d72b4cc89504811c7b73e35aafe9a4011e5\nqcow2:          ae3acbc9afa8886b03ce112d57177e7a9e0a05819d3f0d7bba9fc0e2663fddf5\nvmdk:           a926054ee74e3fa6193efc467be82ad7ff041e58db6712cabf19a82793cbc345\novf:            02baf8c99f0322217499ddf7ca5f853b74f37926ab7739efc2e7e6dd87ecc8c1\narchive:        beb1ba4cddc9a18f49f190d33d9a3ef0221b90d19683f810f170ec4629c55f39\nBuild complete!\n</code></pre> <p>Verify that under the output/qcow2 folder we have our image ready to be used.</p> <pre><code> ~/ \u2593\u2592\u2591 tree output\noutput\n\u251c\u2500\u2500 manifest-qcow2.json\n\u2514\u2500\u2500 qcow2\n    \u2514\u2500\u2500 disk.qcow2\n</code></pre>"},{"location":"use-cases/bootc-image-builder-qcow/#create-the-vm-in-kvm","title":"Create the VM in KVM","text":"<p>We will now use the image to spin up our Virtual Machine in KVM.</p> <pre><code>sudo virt-install \\\n    --name rhel-bootc-vm \\\n    --vcpus 4 \\\n    --memory 4096 \\\n    --import --disk ./output/qcow2/disk.qcow2,format=qcow2 \\\n    --os-variant rhel10.0 \\\n    --network network=default\n</code></pre> <p>Wait for the VM to be ready and retrieve the IP address for the domain to log-in using SSH using bootc-user/redhat credentials:</p> <pre><code> ~ \u2593\u2592\u2591 VM_IP=$(sudo virsh -q domifaddr rhel-bootc-vm | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\nWarning: Permanently added '192.168.150.157' (ED25519) to the list of known hosts.\nbootc-user@192.168.150.157's password:\n[bootc-user@localhost ~]$ curl localhost\nWelcome to the bootc-http instance!\n[bootc-user@localhost ~]$\n</code></pre>"},{"location":"use-cases/image-mode-management-insights/","title":"Use Case - Managing a RHEL Image Mode instance with Red Hat Insights.","text":"<p>In this example, we will build a container image from a Containerfile and we will generate a QCOW image to spin up a Virtual Machine in KVM and manage it with Red Hat Insights</p> <p>The Containerfile in the example:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs Insights Client</li> <li>Adds a custom Message of the Day</li> </ul> Review Containerfile.insights <pre><code>LABEL org.opencontainers.image.authors=\"alerossi@redhat.com\"\nFROM registry.redhat.io/rhel10/rhel-bootc:10.1\nRUN dnf -y install tmux mkpasswd insights-client\nRUN pass=$(mkpasswd --method=SHA-512 --rounds=4096 redhat) &amp;&amp; useradd -m -G wheel bootc-user -p $pass\nRUN echo \"%wheel        ALL=(ALL)       NOPASSWD: ALL\" &gt; /etc/sudoers.d/wheel-sudo\nRUN echo \"This is a RHEL 10 VM installed using a bootable container with Red Hat Insights installed!\" &gt; /etc/motd.d/10-first-setup.motd\n</code></pre>"},{"location":"use-cases/image-mode-management-insights/#building-the-image","title":"Building the image","text":"<p>From the root folder of the repository, switch to the use case directory:</p> <pre><code>cd use-cases/image-mode-management-insights\n</code></pre> <p>To build the image:</p> <pre><code>podman build -f Containerfile.insights -t rhel-bootc-vm:insights .\n</code></pre>"},{"location":"use-cases/image-mode-management-insights/#tagging-and-pushing-the-image","title":"Tagging and pushing the image","text":"<p>To tag and push the image you can simply run (replace YOURQUAYUSERNAME with the account name):</p> <pre><code>export QUAY_USER=YOURQUAYUSERNAME\n</code></pre> <pre><code>podman tag rhel-bootc-vm:ami quay.io/$QUAY_USER/rhel-bootc-vm:insights\n</code></pre> <p>Log-in to Quay.io:</p> <pre><code>podman login -u $QUAY_USER quay.io\n</code></pre> <p>And push the image:</p> <pre><code>podman push quay.io/$QUAY_USER/rhel-bootc-vm:insights\n</code></pre>"},{"location":"use-cases/image-mode-management-insights/#generating-the-qcow-image","title":"Generating the QCOW image","text":"<p>To generate the QCOW image we will be using bootc-image-builder container image that will help us transitioning from our newly generated bootable container image to a VM image that can be used with KVM.</p> <p>Let's proceed with the QCOW image creation:</p> <pre><code>sudo podman run \\\n    --rm \\\n    -it \\\n    --privileged \\\n    --pull=newer \\\n    --security-opt label=type:unconfined_t \\\n    -v $(pwd)/output:/output \\\n    -v /var/lib/containers/storage:/var/lib/containers/storage \\\n    registry.redhat.io/rhel10/bootc-image-builder:latest \\\n    build \\\n    --type qcow2 \\\n    quay.io/$QUAY_USER/rhel-bootc-vm:insights\n</code></pre> <p>We will use the local image we just copied to save in the output folder our generated image.</p> <p>The process will take care of all required steps (deploying the image, SELinux configuration, filesystem configuration, ostree configuration, etc.), after a couple of minutes we will find in the output:</p> <pre><code>Generating manifest-qcow2.json ... DONE\nBuilding manifest-qcow2.json\nstarting -Pipeline source org.osbuild.containers-storage: 8aaabad5f0c2c00eb12666076be4e6843f04e262230e2976dbb1218e96f2ca53\nBuild\n  root: &lt;host&gt;\nPipeline build: 2fb8b2a9ec9dc564950ddc6213d923bdd036c2328a97d0bb785c72fb5b6e1154\nBuild\n  root: &lt;host&gt;\n  runner: org.osbuild.rhel82 (org.osbuild.rhel82)\n[...]\n\n\u23f1  Duration: 81s\nmanifest - finished successfully\nbuild:          2fb8b2a9ec9dc564950ddc6213d923bdd036c2328a97d0bb785c72fb5b6e1154\nimage:          a578f97344212ef8cdc1a53717b61d72b4cc89504811c7b73e35aafe9a4011e5\nqcow2:          ae3acbc9afa8886b03ce112d57177e7a9e0a05819d3f0d7bba9fc0e2663fddf5\nvmdk:           a926054ee74e3fa6193efc467be82ad7ff041e58db6712cabf19a82793cbc345\novf:            02baf8c99f0322217499ddf7ca5f853b74f37926ab7739efc2e7e6dd87ecc8c1\narchive:        beb1ba4cddc9a18f49f190d33d9a3ef0221b90d19683f810f170ec4629c55f39\nBuild complete!\n</code></pre> <p>Verify that under the output/qcow2 folder we have our image ready to be used.</p> <pre><code> ~/ \u2593\u2592\u2591 tree output\noutput\n\u251c\u2500\u2500 manifest-qcow2.json\n\u2514\u2500\u2500 qcow2\n    \u2514\u2500\u2500 disk.qcow2\n</code></pre>"},{"location":"use-cases/image-mode-management-insights/#create-the-vm-in-kvm","title":"Create the VM in KVM","text":"<p>We will now use the image to spin up our Virtual Machine in KVM.</p> <pre><code>sudo virt-install \\\n    --name rhel-bootc-vm \\\n    --vcpus 4 \\\n    --memory 4096 \\\n    --import --disk ./output/qcow2/disk.qcow2,format=qcow2 \\\n    --os-variant rhel10.4 \\\n    --network network=default\n</code></pre>"},{"location":"use-cases/image-mode-management-insights/#register-the-vm-with-red-hat-insights","title":"Register the VM with Red Hat Insights","text":"<p>Once the VM is up and running, log-in using the bootc-user/redhat credentials:</p> <pre><code>VM_IP=$(sudo virsh -q domifaddr rhel-bootc-vm | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\n</code></pre> <p>Register the VM with Red Hat Subscription Manager using your Red Hat ID:</p> <pre><code>sudo subscription-manager register\n</code></pre> <p>And then register it with Red Hat Insights:</p> <pre><code>sudo insights-client --register\n</code></pre> <p>After some seconds, the data will be uploaded and you can browse to Red Hat Insights to check that your new host is registered.</p> <p>If you go in the host itself (it should be registered as localhost) you will see a dedicated section called BOOTC where information about the current image in use is shown, as in the picture.</p> <p></p>"},{"location":"use-cases/image-mode-management-insights/#optional-update-the-image-and-visualize-the-changes-on-red-hat-insights","title":"Optional - Update the image and visualize the changes on Red Hat Insights","text":"<p>For showcasing how Red Hat Insights supports image updates, we also have an updated version, that adds an additional motd.</p> Review Containerfile.insights-update <pre><code>LABEL org.opencontainers.image.authors=\"alerossi@redhat.com\"\nFROM registry.redhat.io/rhel10/rhel-bootc:10.1\nRUN dnf -y install tmux mkpasswd insights-client\nRUN pass=$(mkpasswd --method=SHA-512 --rounds=4096 redhat) &amp;&amp; useradd -m -G wheel bootc-user -p $pass\nRUN echo \"%wheel        ALL=(ALL)       NOPASSWD: ALL\" &gt; /etc/sudoers.d/wheel-sudo\nRUN echo \"This is a RHEL 10 VM installed using a bootable container with Red Hat Insights installed!\" &gt; /etc/motd.d/10-first-setup.motd\nRUN echo \"The VM was updated using a newer version of the image\" &gt; /etc/motd.d/20-update.motd\n</code></pre>"},{"location":"use-cases/image-mode-management-insights/#building-the-image_1","title":"Building the image","text":"<p>From the root folder of the repository, switch to the use case directory:</p> <pre><code>cd use-cases/image-mode-management-insights\n</code></pre> <p>To build the image:</p> <pre><code>podman build -f Containerfile.insights-update -t rhel-bootc-vm:insights .\n</code></pre>"},{"location":"use-cases/image-mode-management-insights/#tagging-and-pushing-the-image_1","title":"Tagging and pushing the image","text":"<p>To tag and push the image you can simply run (replace YOURQUAYUSERNAME with the account name):</p> <pre><code>export QUAY_USER=YOURQUAYUSERNAME\n</code></pre> <pre><code>podman tag rhel-bootc-vm:ami quay.io/$QUAY_USER/rhel-bootc-vm:insights\n</code></pre> <p>Log-in to Quay.io:</p> <pre><code>podman login -u $QUAY_USER quay.io\n</code></pre> <p>And push the image:</p> <pre><code>podman push quay.io/$QUAY_USER/rhel-bootc-vm:insights\n</code></pre>"},{"location":"use-cases/image-mode-management-insights/#updating-the-vm-using-the-new-image","title":"Updating the VM using the new image","text":"<p>Once the VM is up and running, log-in using the bootc-user/redhat credentials:</p> <pre><code>VM_IP=$(sudo virsh -q domifaddr rhel-bootc-vm | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\n</code></pre> <p>Run the bootc upgrade command to update the OS to the lastest version:</p> <pre><code>sudo bootc upgrade\n</code></pre> <p>Run the insights-client utility to see the changes, as the new image will be shown as available and no rollback images is available since the upgrade still isn't applied.</p> <pre><code>sudo insights-client\n</code></pre> <p>Verify on the Console that you see the updated info on the image:</p> <p></p> <p>Reboot the VM to apply the new update:</p> <pre><code>sudo reboot\n</code></pre> <p>And then re-run the Insights-client upload:</p> <pre><code>sudo insights-client\n</code></pre> <p>Now the new version is applied, and if you check the console, no new update is scheduled, but you can see the rollback image pointing to the pre-upgrade image:</p> <p></p>"},{"location":"use-cases/image-mode-way-of-working/","title":"Ways of working with Image Mode for RHEL","text":"<p>In this example, we will build upon what we have learned from the previous examples. We will create a number of Image Mode container images where the images will be \"inheriting\" from the base images.</p> <p>We will create a Standard Operating Environment (SOE) image, also called a \"golden image\" that can be reused in all RHEL deployments.. The services images, running specific systemd services such as httpd or mariadb, are build on top of the base image, and the applications deployed upon the services images. We will build a web server and deploy a MariaDB serverand go through the life-cycle of upgrading the servers.</p> <p>There are two practices on building the systemd services images. The first is to build the services directly into the image based on the RHEL image from the <code>registry.redhat.io</code>. The second is what we will build in this example, create an base image (soe image) and reuse that image to build our services and applications.</p>"},{"location":"use-cases/image-mode-way-of-working/#the-build-process","title":"The Build process","text":"<p>The following Container files with the content will be built:</p> <ul> <li>soe-rhel<ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Adds a custom Message of the Day</li> </ul> </li> <li>httpd<ul> <li>use the soe-rhel image</li> <li>Installs Apache Server</li> <li>Enables the systemd unit for httpd</li> <li>Move the www directory from var to usr</li> <li>Copy our simple webpage content</li> <li>Update the message of the day</li> </ul> </li> <li>homepage<ul> <li>use the httpd image</li> <li>copy our Image Mode webpage content</li> </ul> </li> <li>database<ul> <li>use the soe-rhel image</li> <li>Installs Mariadb</li> <li>Copy the Mariadb config file</li> <li>Enables the systemd unit for Mariadb</li> </ul> </li> </ul>"},{"location":"use-cases/image-mode-way-of-working/#the-workflow","title":"The workflow","text":"<ol> <li>Create a RHEL 9.6 base image</li> <li>Create our application images and VMs.<ol> <li>Create a httpd server image based on our RHEL 9.6 base image</li> <li>Create a MariaDB server image based on our RHEL 9.6 base image</li> </ol> </li> <li>Deploy the application images as a virtual machine servers.</li> <li>Create the homepage image with our 9 homepage content and switch the VM to the homepage image.</li> <li>Rollback to get our old homepage back up and running.</li> <li>Fix the error in the homepage container file and update the VM.</li> <li>Upgrade the base RHEL image to RHEL 10.</li> <li>Build a new version of the httpd service image on RHEL 10.</li> <li>Build a new version of the homepage image containing the RHEL 10 homepage.</li> <li>Upgrade the Homepage VM to the latest 10 homepage and the OS to RHEL version 10.</li> <li>Upgrade the Database server to RHEL 10.</li> </ol>"},{"location":"use-cases/image-mode-way-of-working/chapter1/","title":"Chapter 1 - Working with Golden Images","text":""},{"location":"use-cases/image-mode-way-of-working/chapter1/#build-the-demo-base-image-for-rhel","title":"Build the demo base image for RHEL","text":"<p>The first steps we will build our base SOE (golden) image that we are going to use within the workshop. We will start with RHEL 9 and during the workshop update to RHEL 10.</p> <p>We will name our SOE (Standard Operating Environment/Golden) image <code>soe-rhel:9</code> and also tag it as our latest rhel base image as <code>soe-rhel:latest</code>.</p> <ol> <li> <p>Use podman to build our soe base RHEL \"golden image\". Change to the directory where you have cloned this repo and use <code>podman build</code> to build the image from the <code>Containerfile</code>. The following command will work if you cloned it into your home directory.</p> <pre><code>cd $HOME/redhat-image-mode-demo/use-cases/image-mode-way-of-working/soe-rhel9\n</code></pre> <p> Review soe-rhel9/Containerfile <pre><code>FROM registry.redhat.io/rhel9/rhel-bootc:latest\n\nRUN dnf -y install mkpasswd\nRUN pass=$(mkpasswd --method=SHA-512 --rounds=4096 redhat) &amp;&amp; useradd -m -G wheel bootc-user -p $pass\n\nADD etc/ /etc\n</code></pre> </p> <pre><code>podman build -t quay.io/$QUAY_USER/soe-rhel:latest -t quay.io/$QUAY_USER/soe-rhel:9 -f Containerfile\n</code></pre> </li> <li> <p>If we want to test our image we can run it in a container. You can log in with user <code>bootc-user</code> and password <code>redhat</code> and run <code>curl localhost</code> to test if the httpd service is running and you can see the base image welcome page. You can stop and exit the container with <code>sudo halt</code>. We are going to run our container in the next step to check that the httpd service is running and that we can see our homepage before deploying it to a VM.</p> <pre><code>podman run -it --rm --name soe-rhel9 -p 8080:80 quay.io/$QUAY_USER/soe-rhel:9\n</code></pre> </li> <li> <p>Push the base rhel image to our registry.</p> <pre><code>podman push quay.io/$QUAY_USER/soe-rhel:latest &amp;&amp; podman push quay.io/$QUAY_USER/soe-rhel:9\n</code></pre> </li> </ol> <p>Tip</p> <p>We could base the initial image on an older release of RHEL, such as <code>rhel:9.6</code>, or a specific timestamp version of RHEL such as <code>rhel:9.6-1747275992</code>, or fix it at a certain release such as <code>rhel:9.7</code>, instead of pulling the latest release by specifying the release number in the Containerfile <code>FROM</code> statement.</p>"},{"location":"use-cases/image-mode-way-of-working/chapter1/#deploying-the-homepage-virtual-machine","title":"Deploying the Homepage Virtual Machine","text":"<p>We need to create an image for our httpd service based on the RHEL 9 base image we created in the previous step. We will name our httpd service image <code>httpd:rhel9</code> and also tag it as our latest rhel base image as <code>httpd:latest</code>.</p> <ol> <li> <p>Use podman to build httpd service image. Change to the httpd-service folder.</p> <pre><code>cd ../httpd-service\n</code></pre> <p> Review httpd-service/Containerfile <pre><code>FROM quay.io/$QUAY_USER/soe-rhel:latest\n\nRUN dnf -y install httpd\n\nADD etc/ /etc\n\nRUN &lt;&lt;EOF \n    set -euxo pipefail\n    mv /var/www /usr/share/www\n    sed -i 's-/var/www-/usr/share/www-' /etc/httpd/conf/httpd.conf\nEOF\n\nADD html/ /usr/share/www/html\n\nRUN cp /etc/redhat-release /usr/share/www/html/redhat-release\nRUN cp /etc/os-release /usr/share/www/html/os-release\nRUN uname -sr &gt; /usr/share/www/html/uname.txt\n\nRUN systemctl enable httpd \n\nEXPOSE 80\n</code></pre> </p> </li> <li> <p>Change the $QUAY_USER in the <code>Containerfile</code> to your Quay userid or your registry.</p> </li> <li> <p>Use <code>podman build</code> to build the image from the <code>Containerfile</code>.</p> <pre><code>podman build -t quay.io/$QUAY_USER/httpd:latest -t quay.io/$QUAY_USER/httpd:rhel9 -f Containerfile\n</code></pre> </li> <li> <p>Push the httpd service image to our registry.</p> <pre><code>podman push quay.io/$QUAY_USER/httpd:latest &amp;&amp; podman push quay.io/$QUAY_USER/httpd:rhel9\n</code></pre> </li> <li> <p>If we want to test our image we can run it in a container.     <pre><code>podman run -it --rm --name httpd-rhel9 -p 8080:80 quay.io/$QUAY_USER/httpd:rhel9\n</code></pre></p> </li> <li> <p>You can log in with user <code>bootc-user</code> and password <code>redhat</code> and run <code>curl localhost</code> to test if the httpd service is running and you can see the base image welcome page. You can test the homepage in a browser on the local machine by using the URL <code>http://localhost:8080</code>. You can stop and exit the container with <code>sudo halt</code>.</p> </li> </ol> <p>Now we are ready to create the virtual machine disk image that we are going to import into our new VM.</p> <p>Since we need to run the Image Builder convert tool as superuser we need to pull the image from the registry using sudo to add it to sudo's image repository.</p> <ol> <li> <p>Since we need to run podman as root to build the virtual machine qcow2 image file, we need to pull the image as root.</p> <p>Tip</p> <p>You may also get an error <code>Error: unable to copy from source</code>. You need to go to your repository, in our example, Quay, and make the repositories <code>public</code>.</p> <pre><code>sudo podman pull quay.io/$QUAY_USER/httpd:latest\n</code></pre> </li> <li> <p>We need to use podman to run the Image Mode virtual machine disk builder to pull the image from the registry and create the virtual machine disk file. You can edit the <code>config.toml</code>file to change it to add or replace the user, password, ssh key and more. Refer to Supported image customizations for a configuration file.</p> <p>Tip</p> <p>If you get an error <code>Error: unable to copy from source</code> you may have to do a <code>sudo podman login registry.redhat.io -u $REDHAT_USER -p $REDHAT_PASSWORD</code>.</p> <pre><code>sudo podman run \\\n--rm \\\n-it \\\n--privileged \\\n--pull=newer \\\n--security-opt label=type:unconfined_t \\\n-v $(pwd)/config.toml:/config.toml:ro \\\n-v $(pwd):/output \\\n-v /var/lib/containers/storage:/var/lib/containers/storage registry.redhat.io/rhel9/bootc-image-builder:latest \\\n--type qcow2 \\\nquay.io/$QUAY_USER/httpd:latest\n</code></pre> </li> <li> <p>We will copy the new disk image to the libvirt images pool.</p> <p>Tip</p> <p>You can move the disk image if you don't plan to use it for another VM using the mv command.</p> <pre><code>sudo cp ./qcow2/disk.qcow2 /var/lib/libvirt/images/homepage.qcow2\n</code></pre> </li> <li> <p>Create the VM from the copied virtual machine image qcow2 file. We will give it 4GB of RAM and set the boot option to UEFI.</p> <pre><code>sudo virt-install \\\n--connect qemu:///system \\\n--name homepage \\\n--import \\\n--boot uefi \\\n--memory 4096 \\\n--graphics none \\\n--osinfo rhel9-unknown \\\n--noautoconsole \\\n--noreboot \\\n--disk /var/lib/libvirt/images/homepage.qcow2\n</code></pre> </li> <li> <p>Start the VM.</p> <pre><code>sudo virsh start homepage\n</code></pre> </li> <li> <p>Login via ssh. You can use the following command that will get the IP address from virsh and log you in.</p> <pre><code>VM_IP=$(sudo virsh -q domifaddr homepage | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\n</code></pre> </li> <li> <p>You can run a <code>curl localhost</code> to check if the httpd service with our base image homepage is working. Exit the VM with <code>exit</code>, <code>logout</code> or Ctrl-d.</p> </li> <li> <p>Since we are going to refer to the quay.io registry, let us add $QUAY_USER to our .bashrc file.</p> <pre><code>sed -i '/unset rc[^\\n]*/,$!b;//{x;//p;g};//!H;$!d;x;iexport QUAY_USER=\"your quay.io username not the email address\"' .bashrc\n</code></pre> </li> <li> <p>and reload the .bashrc file to bring QUAY_USER into the variables.</p> <pre><code>source .bashrc\n</code></pre> </li> <li> <p>Finally for this section run the bootc status command to view the booted image registry source and the RHEL version.</p> <pre><code>sudo bootc status\n</code></pre> <pre><code>    Booted image: quay.io/$QUAY_USER/httpd:rhel9 \\\n    Digest: sha256:a48811e05........... \\\n    Version: 9.7 (2025-07-21 13:10:35.887718188 UTC)\n</code></pre> </li> </ol> <p>Our virtual machine based on Image Mode is now running and we are ready to make updates to the web page.</p>"},{"location":"use-cases/image-mode-way-of-working/chapter1/#update-the-homepage-vm-to-our-image-mode-web-page","title":"Update the Homepage VM to our Image Mode web page","text":"<p>The next steps we will update the web page in our <code>homepage</code> VM from the basic RHEL webpage that we created to an more updated web page showing the advantages of using Image Mode.</p> <p>On our image builder server we will build a new Image Mode for RHEL 9 homepage image that we will deploy to the VM.</p> <ol> <li> <p>Change directory to the new web page Container file and the RHEL 9 Image Mode web page at <code>homepage-rhel9</code>. You can open the <code>index.html</code> file in the <code>html</code> directory to see the updates to the homepage.</p> <pre><code>cd ../homepage-rhel9\n</code></pre> </li> <li> <p>Build the new homepage images from the <code>Containerfile</code>.</p> <p> Review homepage-rhel9/Containerfile <pre><code>FROM quay.io/$QUAY_USER/soe-rhel:latest\n\nADD html/ /usr/share/www/html\n\nADD etc/ /etc\n\nRUN cp /etc/redhat-release /usr/share/www/html/redhat-release\nRUN cp /etc/os-release /usr/share/www/html/os-release\nRUN uname -sr &gt; /usr/share/www/html/uname.txt\n\nEXPOSE 80\n</code></pre> </p> <p>Tip</p> <p>Remeber to change the $QUAY_USER in the <code>Containerfile</code> to your repository userid. Remeber to make the homepage repository on your Quay registry public.</p> <pre><code>podman build -t quay.io/$QUAY_USER/homepage:rhel9 -t quay.io/$QUAY_USER/homepage:latest -f Containerfile\n</code></pre> </li> <li> <p>Push the image to the registry using the <code>homepage:rhel9</code> and <code>homepage:latest</code> tags.</p> <pre><code>podman push quay.io/$QUAY_USER/homepage:latest &amp;&amp; podman push quay.io/$QUAY_USER/homepage:rhel9\n</code></pre> </li> <li> <p>Switch to the Homepage virtual machine and login to the <code>homepage</code> VM using ssh.</p> <pre><code>VM_IP=$(sudo virsh -q domifaddr homepage | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\n</code></pre> </li> <li> <p>We are now going to use the <code>bootc switch</code> command to switch the virtual machine to the homepage image in the registry.</p> <p>Tip</p> <p>If you didn't add the <code>$QUAY_USER</code> to the <code>.bashrc</code> file then run the following</p> <pre><code>QUAY_USER=\"your quay.io username not the email address\"\n</code></pre> <pre><code>sudo bootc switch quay.io/$QUAY_USER/homepage:latest\n</code></pre> </li> <li> <p>Let us check the we have staged the new homepage image in the virtual machine.</p> <pre><code>sudo bootc status\n</code></pre> <pre><code>    Staged image: quay.io/$QUAY_USER/homepage:latest \\\n            Digest:  sha256:2be7b1...... \\\n        Version: 9.7 (2025-07-21 15:43:03.624175287 UTC) \\\n        \\\n    \u25cf Booted image: quay.io/$QUAY_USER/soe-rhel:9.7 \\\n            Digest: sha256:a48811...... \\\n        Version: 9.7 (2025-07-21 13:10:35.887718188 UTC)\n</code></pre> </li> <li> <p>and we check that we have the old RHEL 9 homepage without our new Image Mode content.</p> <pre><code>curl localhost\n</code></pre> </li> <li> <p>We need to reboot the virtual machine to activate the new layers and have our new home page.</p> <pre><code>sudo reboot\n</code></pre> </li> <li> <p>Login to the virtual machine to verify that we have a new updated Image Mode homepage.</p> <pre><code>VM_IP=$(sudo virsh -q domifaddr homepage | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\ncurl localhost\n</code></pre> </li> <li> <p>Something went wrong! Our httpd service has failed during the update! Let us check the service.</p> <pre><code>sudo systemctl status httpd\n</code></pre> </li> <li> <p>There is no httpd service. We will rollback in the next section and fix the problem.</p> </li> </ol>"},{"location":"use-cases/image-mode-way-of-working/chapter1/#rollback-and-fix-our-homepage","title":"Rollback and fix our homepage","text":"<p>In the previous section the httpd service wasn't in the image. This is due to a mistake we made in the Containerfile. First, we will rollback so that we have the old homepage up and running, and then we will fix the problem.</p> <p>On our image builder server we will build a new Image Mode for RHEL 9 homepage image that we will deploy to the VM.</p> <ol> <li>In the homepage VM we will issue the rollback command, and use the <code>--apply</code> flag to automatically reboot the VM.</li> </ol> <p><pre><code>sudo bootc rollback --apply\n</code></pre> 2. You should have been exited from the VM. If you aren't in the <code>homepage-rhel9</code> directory then change directory to the new web page Container file and the updated web page at <code>homepage-rhel9</code>. You can open the <code>index.html</code> file in the <code>html</code> directory to see the updates to the homepage.</p> <pre><code>```bash\ncd ../homepage-rhel9\n```\n</code></pre> <ol> <li> <p>We need to fix the Containerfile to pull the correct image from the registry. Use an editor to change the following line to</p> <p>Tip</p> <p>Remeber to change the $QUAY_USER in the <code>Containerfile</code> to your repository userid.</p> <pre><code>FROM quay.io/$QUAY_USER/soe-rhel:latest\n</code></pre> <p>change to</p> <pre><code>FROM quay.io/$QUAY_USER/httpd:latest\n</code></pre> </li> <li> <p>Build the new homepage images from the <code>Containerfile</code> and tag to a new version <code>homepage:rhel9-fix</code>.</p> <pre><code>podman build -t quay.io/$QUAY_USER/homepage:rhel9-fix -t quay.io/$QUAY_USER/homepage:latest -f Containerfile\n</code></pre> </li> <li> <p>Push the image to the registry using the <code>homepage:rhel9-fix</code> and <code>homepage:latest</code> tags.</p> <pre><code>podman push quay.io/$QUAY_USER/homepage:latest &amp;&amp; podman push quay.io/$QUAY_USER/homepage:rhel9-fix\n</code></pre> </li> <li> <p>Switch to the Homepage virtual machine and login to the <code>homepage</code> VM using ssh.</p> <pre><code>VM_IP=$(sudo virsh -q domifaddr homepage | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\n</code></pre> </li> <li> <p>We are going to use the <code>bootc switch</code> command to switch the virtual machine to the homepage image in the registry.</p> <p>Tip</p> <p>If you didn't add the <code>$QUAY_USER</code> to the <code>.bashrc</code> file then run the following</p> <pre><code>QUAY_USER=\"your quay.io username not the email address\"\n</code></pre> <pre><code>sudo bootc switch quay.io/$QUAY_USER/homepage:latest\n</code></pre> </li> <li> <p>Let us check the we have staged the new homepage image in the virtual machine.</p> <pre><code>sudo bootc status\n</code></pre> <pre><code>    Staged image: quay.io/$QUAY_USER/homepage:latest \\\n            Digest:  sha256:2be7b1...... \\\n        Version: 9.7 (2025-07-21 15:43:03.624175287 UTC) \\\n        \\\n    \u25cf Booted image: quay.io/$QUAY_USER/soe-rhel:9.7 \\\n            Digest: sha256:a48811...... \\\n        Version: 9.7 (2025-07-21 13:10:35.887718188 UTC)\n</code></pre> </li> <li> <p>and we check that we have the old RHEL 9 homepage without our new Image Mode content.</p> <pre><code>curl localhost\n</code></pre> </li> <li> <p>We need to reboot the virtual machine to activate the new layers and have our new home page.</p> <pre><code>sudo reboot\n</code></pre> </li> <li> <p>Login to the virtual machine to verify that we have a new updated Image Mode homepage.</p> <pre><code>VM_IP=$(sudo virsh -q domifaddr homepage | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\n</code></pre> <pre><code>curl localhost\n</code></pre> </li> </ol>"},{"location":"use-cases/image-mode-way-of-working/chapter1/#build-the-database-virtual-machine","title":"Build the database virtual machine","text":"<p>We will then deploy a new virtual machine named <code>database</code> as this will be our new demo database server. We will build the two images in one linked command and push it as the version 1 and latest images to our registry.</p> <p>We are following a less complex deployment for the database server than the deployment we did for the homepage. We are going to deploy the mariadb service using a bash script to automate the deployment.</p> <p>In the <code>mariadb_service</code> directory update the QUAY_USER variable in the <code>mariadb-deploy-rhel9.sh</code> file and the <code>Containerfile</code> with your quay user id.</p> Review mariadb-service/mariadb-deploy-rhel9.sh <pre><code>#! /bin/bash\n# This script deploys a MariaDB database using Podman.\n\nQUAY_USER=\"your quay username\"\n\npodman build -t quay.io/$QUAY_USER/database:latest -t quay.io/$QUAY_USER/database:rhel9.6 -f Containerfile\npodman push quay.io/$QUAY_USER/database:latest &amp;&amp; podman push quay.io/$QUAY_USER/database:rhel9.6\n\nsudo podman pull quay.io/$QUAY_USER/database:latest\nsudo podman run \\\n--rm \\\n-it \\\n--privileged \\\n--pull=newer \\\n--security-opt label=type:unconfined_t \\\n-v $(pwd)/config.toml:/config.toml:ro \\\n-v $(pwd):/output \\\n-v /var/lib/containers/storage:/var/lib/containers/storage registry.redhat.io/rhel9/bootc-image-builder:latest \\\n--type qcow2 \\\n--tls-verify=false \\\nquay.io/$QUAY_USER/database:latest\n\nsudo mv qcow2/disk.qcow2 /var/lib/libvirt/images/database.qcow2\n\nsudo virt-install \\\n  --connect qemu:///system \\\n  --name database \\\n  --import \\\n  --boot uefi \\\n  --memory 4096 \\\n  --graphics none \\\n  --osinfo rhel9-unknown \\\n  --noautoconsole \\\n  --noreboot \\\n  --disk /var/lib/libvirt/images/database.qcow2\n\nsudo virsh start database\n</code></pre> <p>and the Containerfile</p> Review mariadb-service/Containerfile <pre><code>FROM quay.io/$QUAY_USER/soe-rhel:latest\n\nADD etc/ /etc\n\nRUN dnf -y install mariadb mariadb-server vim &amp;&amp; dnf clean all &amp;&amp; rm -rf /var/cache /var/log/dnf &amp;&amp; systemctl enable mariadb\n\nCOPY ./files/00-mariadb-tmpfile.conf /usr/lib/tmpfiles.d/\n\nEXPOSE 3306\n</code></pre> <ol> <li> <p>Change to the <code>mariadb-service</code> directory.</p> <pre><code>cd ../mariadb-service\n</code></pre> </li> <li> <p>Ensure that the <code>mariadb-deploy.sh</code> file is executable.</p> <pre><code>chmod +x mariadb-deploy.sh\n</code></pre> </li> <li> <p>Edit the mariadb-deploy.sh file and change the entry for the QUAY_USER to your quay.io user name.</p> </li> <li> <p>Run the bash script <code>mariadb-deploy.sh</code> to create the database images and the database VM.</p> <pre><code>./mariadb_deploy.sh\n</code></pre> </li> </ol> <p>This will build and push the mariadb service image and deploy the VM from the image.</p>"},{"location":"use-cases/image-mode-way-of-working/chapter2/","title":"Chapter 2 - Working with updates and upgrades","text":""},{"location":"use-cases/image-mode-way-of-working/chapter2/#create-a-new-rhel-10-base-image","title":"Create a new RHEL 10 base image","text":"<p>We are going to create a new soe-rhel base image that is based on the latest RHEL, version 10. This base image we are going to use to upgrade our services, httpd and mariadb. We created a new RHEL 10 homepage and then will upgrade the VMs to RHEL 10.</p> <ol> <li> <p>Change to the RHEL 10 Container file directory to build the new RHEL 10 base image.</p> <pre><code>cd ../soe-rhel10.0\n</code></pre> </li> <li> <p>Use Podman build to build the new RHEL 10 image and tag it as <code>soe-rhel:latest</code> and <code>soe-rhel:10</code>.</p> <p> Review soe-rhel10/Containerfile <pre><code>FROM registry.redhat.io/rhel10/rhel-bootc:latest\n\nRUN dnf -y install mkpasswd\nRUN pass=$(mkpasswd --method=SHA-512 --rounds=4096 redhat) &amp;&amp; useradd -m -G wheel bootc-user -p $pass\n\nADD etc/ /etc\n</code></pre> </p> <pre><code>podman build -t quay.io/$QUAY_USER/soe-rhel:latest -t quay.io/$QUAY_USER/soe-rhel:10 -f Containerfile\n</code></pre> </li> <li> <p>Push the new images to the registry.</p> <pre><code>podman push quay.io/$QUAY_USER/soe-rhel:latest &amp;&amp; podman push quay.io/$QUAY_USER/soe-rhel:10\n</code></pre> </li> </ol>"},{"location":"use-cases/image-mode-way-of-working/chapter2/#upgrade-the-vm-to-rhel-10-and-update-the-homepage","title":"Upgrade the VM to RHEL 10 and update the homepage","text":"<p>Next we are going to build the httpd services image on RHEL 10 and upgrade the homepage VM.</p> <ol> <li> <p>Change directory to the httpd-service directory. Since we base our httpd image on the latest tagged RHEL base image in the repository, we can reuse the same Container file.</p> <pre><code>cd ../httpd-service\n</code></pre> </li> <li> <p>Use Podman build to build the new httpd images and we will tag the images as <code>httpd:latest</code> and <code>httpd:rhel10</code>. It is best practice to tag these images with version numbers or date stamps, but for the demo it makes it easier to track the RHEL version we are using.</p> <p>Tip</p> <p>Remeber to change the $QUAY_USER in the <code>Containerfile</code> to your repository userid.</p> <p> Review httpd-service/Containerfile <pre><code>FROM quay.io/$QUAY_USER/soe-rhel:latest\n\nRUN dnf -y install httpd\n\nADD etc/ /etc\n\nRUN &lt;&lt;EOF \n    set -euxo pipefail\n    mv /var/www /usr/share/www\n    sed -i 's-/var/www-/usr/share/www-' /etc/httpd/conf/httpd.conf\nEOF\n\nADD html/ /usr/share/www/html\n\nRUN cp /etc/redhat-release /usr/share/www/html/redhat-release\nRUN cp /etc/os-release /usr/share/www/html/os-release\nRUN uname -sr &gt; /usr/share/www/html/uname.txt\n\nRUN systemctl enable httpd \n\nEXPOSE 80\n</code></pre> </p> <pre><code>podman build -t quay.io/$QUAY_USER/httpd:latest -t quay.io/$QUAY_USER/httpd:rhel10 -f Containerfile\n</code></pre> </li> <li> <p>Push the new httpd services to the registry.</p> <pre><code>podman push quay.io/$QUAY_USER/httpd:latest &amp;&amp; podman push quay.io/$QUAY_USER/httpd:rhel10\n</code></pre> </li> <li> <p>Change to the homepage-rhel10 directory. This has an updated homepage for RHEL 10 with RHEL 10 logos.</p> <pre><code>cd ../homepage-rhel10\n</code></pre> </li> <li> <p>Build the new homepage images with the tags <code>homepage:latest</code> and <code>homepage:rhel10</code>. We fixed the ContainerFile in the previous section, and it will now use the httpd image and deploy correctly.</p> <pre><code>podman build -t quay.io/$QUAY_USER/homepage:latest -t quay.io/$QUAY_USER/homepage:rhel10 -f Containerfile\n</code></pre> </li> <li> <p>Push the updated homepage images to the registry.</p> <pre><code>podman push quay.io/$QUAY_USER/homepage:latest &amp;&amp; podman push quay.io/$QUAY_USER/homepage:rhel10\n</code></pre> </li> <li> <p>No we switch to the <code>homepage</code> VM, we will use our special ssh command to log into the VM.</p> <pre><code>VM_IP=$(sudo virsh -q domifaddr homepage | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\n</code></pre> </li> <li> <p>Let's check if there is an update in the registry using the <code>bootc upgrade --check</code> command.</p> <pre><code>sudo bootc upgrade --check\n</code></pre> <pre><code>    Update available for: docker://quay.io/$QUAY_USER/homepage:latest \\\n    Version: 10.1 \\\n    Digest: sha256:0c5416...... \\\n    Total new layers: 77    Size: 885.4\u00a0MB \\\n    Removed layers:   76    Size: 1.4\u00a0GB \\\n    Added layers:     76    Size: 885.4\u00a0MB\n</code></pre> </li> <li> <p>Apply the upgrage to our VM. This may take a while as we are pulling RHEL 10 and the homepage updates in one go.</p> <pre><code>sudo bootc upgrade\n</code></pre> </li> <li> <p>Use <code>bootc status</code> to check that we have an update and that is shows that the update RHEL version is version 10.</p> <pre><code>sudo bootc status\n</code></pre> <pre><code>    Staged image: quay.io/$QUAY_USER/homepage:latest \\\n            Digest: sha256:0c5416...... \\\n        Version: 10.1 (2025-07-21 17:25:47.229186615 UTC) \\\n    \\\n    \u25cf Booted image: quay.io/$QUAY_USER/homepage:latest \\\n            Digest: sha256:2be7b1...... \\\n        Version: 9.6 (2025-07-21 15:43:03.624175287 UTC) \\\n    \\\n    Rollback image: quay.io/$QUAY_USER/soe-rhel:latest \\\n            Digest: sha256:7c46d6...... \\\n            Version: 9.6 (2025-07-21 16:04:36.100285429 UTC)\n</code></pre> </li> <li> <p>Reboot the VM to change to the new homepage and run RHEL 10!</p> <pre><code>sudo reboot\n</code></pre> </li> <li> <p>We use our special ssh command again to log into the VM.</p> <pre><code>VM_IP=$(sudo virsh -q domifaddr homepage | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\n</code></pre> </li> <li> <p>and check the OS version using <code>bootc status</code></p> <pre><code>sudo bootc status\n</code></pre> </li> <li> <p>Finally use the VMs ip address and go to the web site to confirm the web page upgrade showing RHEL 10 logos.</p> </li> </ol> <p>This is to show how we update the base OS on an existing deployment. Usually this will be done during an application, or in this case, a homepage update.</p>"},{"location":"use-cases/image-mode-way-of-working/chapter2/#upgrade-the-database-server-to-rhel-10","title":"Upgrade the database server to RHEL 10","text":"<p>Similar we are going to build the database services image on RHEL 10 and upgrade the database VM. Since we don't have any application tied to the database we can upgrade our database VM directly from the database services image.</p> <ol> <li> <p>Change directory to the mariadb-service directory. Since we base our database service image on the latest tagged RHEL base image in the repository, we can reuse the same Container file.</p> <pre><code>cd ../mariadb-service\n</code></pre> </li> <li> <p>Use Podman build to build the new httpd images and we will tag the images as <code>database:latest</code> and <code>database:rhel10</code>. It is best practice to tag these images with version numbers or date stamps, but for the demo it makes it easier to track the RHEL version we are using.</p> <pre><code>podman build -t quay.io/$QUAY_USER/database:latest -t quay.io/$QUAY_USER/database:rhel10 -f Containerfile\n</code></pre> </li> <li> <p>Push the new httpd services to the registry.</p> <pre><code>podman push quay.io/$QUAY_USER/database:latest &amp;&amp; podman push quay.io/$QUAY_USER/database:rhel10\n</code></pre> </li> <li> <p>No we switch to the database VM, we will use our special ssh command to log into the VM.</p> <pre><code>VM_IP=$(sudo virsh -q domifaddr database | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\n</code></pre> </li> <li> <p>Let's check if there is an update in the registry using the <code>bootc upgrade --check</code> command.</p> <pre><code>sudo bootc upgrade --check\n</code></pre> <pre><code>    Update available for: docker://quay.io/$QUAY_USER/database:latest \\\n    Version: 10.1 \\\n    Digest: sha256:0c5416...... \\\n    Total new layers: 77    Size: 885.4\u00a0MB \\\n    Removed layers:   76    Size: 1.4\u00a0GB \\\n    Added layers:     76    Size: 885.4\u00a0MB\n</code></pre> </li> <li> <p>Apply the upgrage to our VM. This may take a while as we are pulling RHEL 10 and the homepage updates in one go. Using  <code>--apply</code> the VM will be rebooted after the upgrade is done.</p> <pre><code>sudo bootc upgrade --apply\n</code></pre> </li> <li> <p>Use our special ssh command to log into the VM again.</p> <pre><code>VM_IP=$(sudo virsh -q domifaddr database | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\n</code></pre> </li> <li> <p>Use <code>bootc status</code> to check that we have an update and that is shows that the update RHEL version is version 10.</p> <pre><code>sudo bootc status\n</code></pre> <pre><code>    Staged image: quay.io/$QUAY_USER/homepage:latest \\\n            Digest: sha256:0c5416...... \\\n        Version: 10.1 (2025-07-21 17:25:47.229186615 UTC) \\\n    \\\n    \u25cf Booted image: quay.io/$QUAY_USER/homepage:latest \\\n            Digest: sha256:2be7b1...... \\\n        Version: 9.6 (2025-07-21 15:43:03.624175287 UTC) \\\n    \\\n    Rollback image: quay.io/$QUAY_USER/soe-rhel:latest \\\n            Digest: sha256:7c46d6...... \\\n            Version: 9.6 (2025-07-21 16:04:36.100285429 UTC)\n</code></pre> </li> <li> <p>Finally check that mariadb is running.</p> <pre><code>sudo systemctl status mariadb\n</code></pre> </li> <li> <p>We can also check the Linux OS version.</p> <pre><code>cat /etc/redhat-release\n</code></pre> </li> </ol>"},{"location":"use-cases/image-mode-way-of-working/chapter2/#use-rhels-soft-reboot-feature-to-deploy-an-update-to-the-homepage","title":"Use RHEL's soft-reboot feature to deploy an update to the homepage","text":"<p>In the last steps we are going to push a new RHEL 10 webpage to the homapage server and make use of the RHEL 10 soft-reboot feature to deploy the new layers.</p> <ol> <li> <p>Change to the homepage-rhel10update directory. This has a new homepage for RHEL 10 with more images.</p> <pre><code>cd ../homepage-rhel10update\n</code></pre> </li> <li> <p>Build the new homepage images with the tags <code>homepage:latest</code> and <code>homepage:rhel10update</code>.</p> <p>Tip</p> <p>Remeber to change the $QUAY_USER in the <code>Containerfile</code> to your repository userid.</p> <p> Review homepage-rhel10update/Containerfile <pre><code># FROM quay.io/jvdbreggen/base-rhel:latest\nFROM quay.io/$QUAY_USER/httpd:latest\n\nADD html/ /usr/share/www/html\n\nADD etc/ /etc\n\nEXPOSE 80\n</code></pre> </p> <pre><code>podman build -t quay.io/$QUAY_USER/homepage:latest -t quay.io/$QUAY_USER/homepage:rhel10update -f Containerfile\n</code></pre> </li> <li> <p>Push the updated homepage images to the registry.</p> <pre><code>podman push quay.io/$QUAY_USER/homepage:latest &amp;&amp; podman push quay.io/$QUAY_USER/homepage:rhel10update\n</code></pre> </li> <li> <p>No we switch to the <code>homepage</code> VM, we will use our special ssh command to log into the VM.</p> <pre><code>VM_IP=$(sudo virsh -q domifaddr homepage | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\n</code></pre> </li> <li> <p>Let's check if there is an update in the registry using the <code>bootc upgrade --check</code> command.</p> <pre><code>sudo bootc upgrade --check\n</code></pre> <pre><code>    Update available for: docker://quay.io/$QUAY_USER/homepage:latest \\\n    Version: 10.1 \\\n    Digest: sha256:0c5416...... \\\n    Total new layers: 77    Size: 885.4\u00a0MB \\\n    Removed layers:   76    Size: 1.4\u00a0GB \\\n    Added layers:     76    Size: 885.4\u00a0MB\n</code></pre> </li> <li> <p>Since we want to check that only systemd is rebooted and not the VM we will check the time the VM has been running</p> <pre><code>uptime\n</code></pre> </li> <li> <p>Apply the upgrage to our VM. This should be quick as we are only pulling a few layers. The VM will let us know it is rebooting and as the sshd service will also re-initialise we will be logged out.</p> <pre><code>sudo bootc upgrade --soft-reboot=required --apply\n</code></pre> </li> <li> <p>We use our special ssh command again to log into the VM.</p> <pre><code>VM_IP=$(sudo virsh -q domifaddr homepage | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\n</code></pre> </li> <li> <p>and check the OS version using <code>bootc status</code></p> <pre><code>sudo bootc status\n</code></pre> </li> <li> <p>Finally, use the VMs ip address and go to the web site to confirm the web page upgrade showing the brand new RHEL 10 web page with the additional images.</p> </li> </ol> <p>This is to show how we update the application only with minimal downtime.</p>"},{"location":"use-cases/image-mode-way-of-working/chapter2/#conclusion","title":"Conclusion","text":"<p>This concludes the workshop exercises. We encourage you to try different services and applications based on the base image <code>soe-rhel</code> that we used in these exercise. We also encourage you to build your own base or corporate image and build and deploy servers using it. You can use Podman Desktop for many of the executions that we did in the command line, and using a desktop approach may be easier for you. Finally, we didn't incorporate any pipelines or CI/CD flows in these examples and using these tools to test and deploy updates makes the task of a system administrator a lot easier. Our Youtube channel \"Into the Terminal\" episode 151 has a great introduction to this.</p>"},{"location":"use-cases/image-mode-way-of-working/demo-build/","title":"Configuring the demo","text":""},{"location":"use-cases/image-mode-way-of-working/demo-build/#set-the-environment","title":"Set the environment","text":"<p>As in the previous use-cases you require system or systems running podman, libvirt and have access to a container registry. A web browser that can access the VMs is helpful to view the results of the web page changes.</p> <p>We will be pushing to Red Hat Quay, but if you have your own registry, or have access to a corporate registry we highly recommend using those registries as you can then continue using these to build your own RHEL images going forward.</p> <p>We will be referring to <code>quay.io\\$QUAY_USER</code> where <code>$QUAY_USER</code> is a variable of your Quay userid, and <code>$REDHAT_USER</code> as your Red Hat userid to pull from <code>registry.redhat.io</code>.</p> <p>We recommend that you set two variables in the terminal you are using for the logins to the Red Hat Registry and Quay.io, as that allows you to use the copy icon in the command line boxes.</p> <p>Using Quay we recommend that when you push the images to Quay that you make the repositories public by selecting the repository and using the Actions to set Make Public Update the variables QUAY_USER and REDHAT_USER with your Quay and Red Hat account userids. They may be the same if you use your Red Hat account. Replace <code>$QUAY_PASSWORD</code> and <code>$REDHAT_PASSWORD</code> with your passwords. If you decide to use these variables, we recommend you hash encrypt the passwords in the variables.</p> <pre><code>QUAY_USER=\"your quay.io username not the email address\"\nREDHAT_USER=\"your Red Hat username, full email address may no longer work\"\nUSER_ID=$(id -ur)\npodman login -u $QUAY_USER quay.io -p $QUAY_PASSWORD &amp;&amp; podman login -u $REDHAT_USER registry.redhat.io -p $REDHAT_PASSWORD\nsudo mkdir -p /run/containers/0\nsudo cp /run/user/$USER_ID/containers/auth.json /run/containers/0/auth.json\n</code></pre>"}]}